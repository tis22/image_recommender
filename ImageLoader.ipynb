{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ExifTags\n",
    "import uuid\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "from scipy.spatial import distance \n",
    "from sklearn.metrics import pairwise_distances\n",
    "from numba import jit, prange\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import pairwise\n",
    "import time\n",
    "import sqlite3\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrival Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load all image paths and get the total number of images,\n",
    "we can't use tqdm here, because we have to determine the number of images first.\n",
    "'''\n",
    "\n",
    "def find_image_files(root_dir, extensions=('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif')):\n",
    "    image_files = []\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(extensions):\n",
    "                image_files.append(os.path.join(subdir, file))\n",
    "    return image_files\n",
    "\n",
    "\n",
    "# here was: image_paths = find_image_files(r\"\")\n",
    "# df_image_paths = pd.DataFrame({'ID': range(1, len(image_paths) + 1), 'Path': image_paths})\n",
    "# df_image_paths = pd.DataFrame(image_paths, columns=[\"Path\"])\n",
    "# df_image_paths.to_pickle('Path.pkl')\n",
    "\n",
    "\n",
    "# Show first 10 paths\n",
    "# print(f\"Number found images: {len(image_paths)}\")\n",
    "# if len(image_paths) > 10:\n",
    "#     print(\"Some paths:\")\n",
    "#     for pic_path in image_paths[:10]:\n",
    "#         print(pic_path)\n",
    "# else:\n",
    "#     print(\"Found paths:\", image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement functions\n",
    "\n",
    "def image_rgb_calculation(image):\n",
    "    # OpenCV uses BGR color space, we have to convert it to the RGB color space\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Calculate the histogram\n",
    "    hist = cv2.calcHist([rgb_image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    \n",
    "    # Normalize the histogram so that histograms of different images (different sizes, resolutions) are comparable\n",
    "    hist = cv2.normalize(hist, hist)\n",
    "    hist = hist.flatten()\n",
    "    return hist\n",
    "\n",
    "\n",
    "def image_hsv_calculation(image):\n",
    "    # OpenCV uses BGR color space, we have to convert it to the RGB color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Calculate the histogram (bin-sizes = 8, values from 0-255)\n",
    "    hist = cv2.calcHist([hsv_image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    \n",
    "    # Normalize the histogram so that histograms of different images (different sizes, resolutions) are comparable\n",
    "    hist = cv2.normalize(hist, hist)\n",
    "    hist = hist.flatten()\n",
    "    return hist\n",
    "\n",
    "\n",
    "# Load the efficientnet_v2_s model\n",
    "model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)\n",
    "\n",
    "# Remove last layer (classificator), because we only need the features\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "model.eval()\n",
    "\n",
    "# Define preprocessing transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def model_embeddings_calculation(image):\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model(input_batch)\n",
    "    features = torch.flatten(features, 1)\n",
    "    \n",
    "    return features.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint.\n",
      "Starting from path with ID: 101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dead38b8e7476eb2ed7bfff9396f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Different Version 2 (more data)\n",
    "\n",
    "\n",
    "def extract_image_details(image_id, path, resize_size):\n",
    "    try:\n",
    "        image = cv2.imread(path)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, resize_size)\n",
    "            rgb_histogram = image_rgb_calculation(image)\n",
    "            hsv_histogram = image_hsv_calculation(image)\n",
    "            model_embedding = model_embeddings_calculation(image)\n",
    "            \n",
    "            ### several more informations ###\n",
    "            \n",
    "            # Convert to RGB\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Calculate average color and brightness\n",
    "            avg_color = np.mean(image_rgb, axis=(0, 1)).tolist()\n",
    "            avg_brightness = np.mean(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "            # Convert to HSV and calculate average HSV\n",
    "            image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            avg_hsv = np.mean(image_hsv, axis=(0, 1)).tolist()\n",
    "\n",
    "            # File details\n",
    "            file_size = os.path.getsize(path)\n",
    "            file_type = os.path.splitext(path)[1]\n",
    "\n",
    "            with Image.open(path) as img:\n",
    "                # Resolution and DPI\n",
    "                resolution = img.size  # (width, height)\n",
    "                dpi = img.info.get('dpi', (0, 0))\n",
    "                \n",
    "                # Extract metadata\n",
    "                try:\n",
    "                    exif_data = img._getexif()\n",
    "                    metadata = {ExifTags.TAGS.get(k, k): v for k, v in exif_data.items()} if exif_data else {}\n",
    "                except AttributeError:\n",
    "                    metadata = {}\n",
    "            \n",
    "            \n",
    "            #################################\n",
    "            \n",
    "            \n",
    "            return {\n",
    "                'ID': image_id,\n",
    "                'Path': path,\n",
    "                'RGB_Histogram': rgb_histogram,\n",
    "                'HSV_Histogram': hsv_histogram,\n",
    "                'Model_Embedding': model_embedding,\n",
    "                'Average_Color': avg_color,\n",
    "                'Brightness': avg_brightness,\n",
    "                'Average_HSV': avg_hsv,\n",
    "                'Resolution': resolution,\n",
    "                'DPI': dpi,\n",
    "                'File_Size': file_size,\n",
    "                'File_Type': file_type,\n",
    "                'Metadata': metadata\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            print(f\"Image at path {path} is None.\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed processing {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "def load_checkpoint():\n",
    "    if not os.path.exists('checkpoint.pkl'):\n",
    "        return 0, [], [], [], [], []\n",
    "    \n",
    "    with open('checkpoint.pkl', 'rb') as f:\n",
    "        batch_index, paths, rgb_hists, hsv_hists, embeddings, other_data = pickle.load(f)\n",
    "        print(f\"Loaded checkpoint.\\nStarting from path with ID: {batch_index + 1}\")\n",
    "\n",
    "    return batch_index, paths, rgb_hists, hsv_hists, embeddings, other_data\n",
    "    \n",
    "    \n",
    "\n",
    "def image_batch_generator(image_files, batch_size, resize_size, start_index = 0, show_progress=True):\n",
    "    total_batches = (len(image_files) - start_index + batch_size - 1) // batch_size # - start_index to display remaining batches correctly\n",
    "    progress_bar = tqdm(total=total_batches, desc=\"Processing images\") if show_progress else None\n",
    "\n",
    "    for index in range(start_index, len(image_files), batch_size):\n",
    "        batch = image_files[index:index + batch_size]\n",
    "        details_list = [extract_image_details(index + i + 1, path, resize_size) for i, path in enumerate(batch)]\n",
    "        details_list = [features for features in details_list if features is not None]\n",
    "        df = pd.DataFrame(details_list)\n",
    "        yield df, index + batch_size\n",
    "        if show_progress:\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    if show_progress:\n",
    "        progress_bar.close()\n",
    "\n",
    "        \n",
    "        \n",
    "# Testing: Example\n",
    "batch_size = 100\n",
    "desired_size = (60, 60)\n",
    "\n",
    "\n",
    "# Load checkpoint\n",
    "start_index, paths, rgb_hists, hsv_hists, embeddings, other_data = load_checkpoint()\n",
    "\n",
    "image_paths = find_image_files(r\"C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\\extra_collection\\beach\")\n",
    "\n",
    "for df, batch_index in image_batch_generator(image_paths, batch_size, desired_size, start_index=start_index, show_progress=True):\n",
    "    paths.extend(df[['ID', 'Path']].values.tolist())\n",
    "    rgb_hists.extend(df[['ID', 'RGB_Histogram']].values.tolist())\n",
    "    hsv_hists.extend(df[['ID', 'HSV_Histogram']].values.tolist())\n",
    "    embeddings.extend(df[['ID', 'Model_Embedding']].values.tolist())\n",
    "    other_data.extend(df.drop(columns=['Path', 'RGB_Histogram', 'HSV_Histogram', 'Model_Embedding']).values.tolist())\n",
    "    \n",
    "    # Save checkpoint, overrides old one and appends new data\n",
    "    with open('checkpoint.pkl', 'wb') as f:\n",
    "        pickle.dump((batch_index, paths, rgb_hists, hsv_hists, embeddings, other_data), f)\n",
    "    \n",
    "\n",
    "# Save results\n",
    "df_paths = pd.DataFrame(paths, columns=[\"ID\", \"Path\"])\n",
    "df_rgb = pd.DataFrame(rgb_hists, columns=[\"ID\", \"Histogram\"])\n",
    "df_hsv = pd.DataFrame(hsv_hists, columns=[\"ID\", \"Histogram\"])\n",
    "df_embeddings = pd.DataFrame(embeddings, columns=[\"ID\", \"Embedding\"])\n",
    "df_other_data = pd.DataFrame(other_data, columns=[\"ID\", \"Average_Color\",\n",
    "                                                 \"Brightness\", \"Average_HSV\",\n",
    "                                                 \"Resolution\",\"DPI\",\n",
    "                                                 \"File_Size\", \"File_Type\",\n",
    "                                                 \"Metadata\"\n",
    "                                                ])\n",
    "\n",
    "df_paths.to_pickle('Path.pkl')\n",
    "df_rgb.to_pickle('RGB_Hist.pkl')\n",
    "df_hsv.to_pickle('HSV_Hist.pkl')\n",
    "df_embeddings.to_pickle('Embeddings.pkl')\n",
    "df_other_data.to_pickle('Other_data.pkl')\n",
    "\n",
    "# Checkpoint can be removed after program was successful\n",
    "if os.path.exists('checkpoint.pkl'):\n",
    "    os.remove('checkpoint.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID                                          Embedding\n",
      "176  177  [-0.18032971, 0.3313287, -0.2374162, -0.217798...\n",
      "177  178  [-0.16402672, 1.7069136, -0.18570574, 0.212251...\n",
      "178  179  [-0.1656731, 0.4096732, -0.1702146, 0.02825574...\n",
      "179  180  [-0.16269362, 1.903489, -0.23513995, 0.0794495...\n",
      "180  181  [-0.02571875, 0.30269966, -0.14092457, 0.06659...\n"
     ]
    }
   ],
   "source": [
    "print(df_embeddings.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_histogram_length = len(df_embeddings.iloc[0]['Embedding'])\n",
    "first_histogram_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID                                          Histogram\n",
      "176  177  [0.010170917, 0.44461438, 0.01598287, 0.0, 0.0...\n",
      "177  178  [0.04859704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "178  179  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "179  180  [0.2950442, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
      "180  181  [0.1805076, 0.029868163, 0.0, 0.0, 0.0, 0.0, 0...\n",
      "      ID                                          Histogram\n",
      "176  177  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "177  178  [0.0, 0.0034040704, 0.0011346901, 0.010212211,...\n",
      "178  179  [0.0, 0.0, 0.0, 0.0006082462, 0.0, 0.001824738...\n",
      "179  180  [0.0, 0.0029820336, 0.0, 0.0, 0.0, 0.0, 0.0, 0...\n",
      "180  181  [0.0, 0.0051383753, 0.017984314, 0.030830253, ...\n",
      "      ID                                               Path\n",
      "176  177  C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\imag...\n",
      "177  178  C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\imag...\n",
      "178  179  C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\imag...\n",
      "179  180  C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\imag...\n",
      "180  181  C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\imag...\n",
      "      ID                                      Average_Color  Brightness  \\\n",
      "176  177  [109.4636111111111, 67.11527777777778, 113.712...   85.089444   \n",
      "177  178            [180.9275, 159.90055555555554, 146.205]  164.628333   \n",
      "178  179  [200.07833333333335, 193.0775, 170.8827777777778]  192.656389   \n",
      "179  180  [136.22916666666666, 88.37527777777778, 60.194...   99.476111   \n",
      "180  181  [138.22416666666666, 154.80027777777778, 164.0...  150.903611   \n",
      "\n",
      "                                           Average_HSV    Resolution  \\\n",
      "176  [139.07722222222222, 132.01694444444445, 133.2...  (5758, 3829)   \n",
      "177  [18.710555555555555, 59.69222222222222, 182.45...  (3311, 4966)   \n",
      "178   [35.4075, 49.92888888888889, 205.38166666666666]  (3456, 5184)   \n",
      "179  [12.673333333333334, 142.7927777777778, 136.34...  (6000, 4000)   \n",
      "180   [86.8175, 51.29361111111111, 166.25611111111112]  (5350, 3567)   \n",
      "\n",
      "          DPI  File_Size File_Type Metadata  \n",
      "176  (72, 72)    2861175      .jpg       {}  \n",
      "177  (72, 72)    4525958      .jpg       {}  \n",
      "178  (72, 72)    2552535      .jpg       {}  \n",
      "179  (72, 72)    2101161      .jpg       {}  \n",
      "180  (72, 72)    1325082      .jpg       {}  \n"
     ]
    }
   ],
   "source": [
    "print(df_rgb.tail())\n",
    "print(df_hsv.tail())\n",
    "print(df_paths.tail())\n",
    "print(df_other_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database\n",
    "\n",
    "# Check if the folder 'databases' does not exist / create it\n",
    "if not os.path.exists('database'):\n",
    "    os.makedirs('database')\n",
    "    \n",
    "conn = sqlite3.connect(\"database/bd_database.db\")\n",
    "curs = conn.cursor()\n",
    "\n",
    "curs.execute(\"\"\"CREATE TABLE IF NOT EXISTS image_paths \n",
    "                (ID INTEGER PRIMARY KEY,\n",
    "                Path text);\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to database\n",
    "path_pickle_df = pd.read_pickle(\"Path.pkl\")\n",
    "\n",
    "for file_path in path_pickle_df['Path']:\n",
    "    curs.execute('''INSERT OR IGNORE INTO image_paths (Path) VALUES (?);''', (file_path,))\n",
    "    # print(f\"Inserted path: {file_path}\")\n",
    "    \n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\0031.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\adam-bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\adrian-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                               Path\n",
       "0    1    C:\\Users\\timsa\\Desktop\\sample_pictures\\0031.png\n",
       "1    2  C:\\Users\\timsa\\Desktop\\sample_pictures\\adam-bi...\n",
       "2    3  C:\\Users\\timsa\\Desktop\\sample_pictures\\adrian-...\n",
       "3    4  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "4    5  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "5    6  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "6    7  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "7    8  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "8    9  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "9   10  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "10  11  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "11  12  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "12  13  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "13  14  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "14  15  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "15  16  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curs.execute(\"\"\"SELECT *\n",
    "                FROM image_paths;\"\"\")\n",
    "results = curs.fetchall()\n",
    "\n",
    "df = pd.DataFrame(results, columns=['ID', 'Path'])\n",
    "\n",
    "#conn.close()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity functions\n",
    "\n",
    "def euclidean_distance():\n",
    "    pass\n",
    "\n",
    "def manhattan_distance():\n",
    "    pass\n",
    "\n",
    "def cosine_similarity():\n",
    "    pass\n",
    "\n",
    "def jaccard_similarity():\n",
    "    pass\n",
    "\n",
    "def hamming_distance():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parts for measurment - dimensionality reduction\n",
    "# needs 1-D-vector\n",
    "\n",
    "\n",
    "def extract_image_details(image_path):\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img = img.convert('RGB')  # Convert to RGB\n",
    "\n",
    "            # Resize image\n",
    "            img_cv = cv2.imread(image_path)\n",
    "            resized = cv2.resize(img_cv, desired_size)\n",
    "            img_as_1d = np.array(resized).flatten() #this could be parallelized\n",
    "\n",
    "            # UUID\n",
    "            unique_id = str(uuid.uuid4())\n",
    "\n",
    "        return {\n",
    "            'ID': unique_id,\n",
    "            'File_Path': image_path,\n",
    "            'Resized_Image_Vector': img_as_1d\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_large_image_dataset(generator, total_images, batch_size, n_components):\n",
    "    \"\"\"\n",
    "    Processes a large image dataset using IncrementalPCA in batches.\n",
    "\n",
    "    Parameters:\n",
    "    generator (generator): Generator yielding batches of image data.\n",
    "    total_images (int): Total number of images in the dataset.\n",
    "    batch_size (int): Number of images to process in each batch.\n",
    "    n_components (int): Number of principal components to keep.\n",
    "\n",
    "    Returns:\n",
    "    IncrementalPCA: The fitted IncrementalPCA model.\n",
    "    \"\"\"\n",
    "    ipca = IncrementalPCA(n_components=n_components)\n",
    "    \n",
    "    for _ in range(0, total_images, batch_size):\n",
    "        batch_df, image_vectors = next(generator)\n",
    "        ipca.partial_fit(image_vectors)\n",
    "    \n",
    "    return ipca\n",
    "\n",
    "\n",
    "def transform_image_features(batch_df, image_vectors, ipca):\n",
    "    \"\"\"\n",
    "    Transforms image features using PCA.\n",
    "\n",
    "    Parameters:\n",
    "    batch_df (pd.DataFrame): The DataFrame containing batch image details.\n",
    "    image_vectors (np.array): The array of image vectors.\n",
    "    ipca (IncrementalPCA): The pre-fitted IncrementalPCA.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The updated DataFrame with PCA vectors added.\n",
    "    \"\"\"\n",
    "    pca_vectors = ipca.transform(image_vectors)\n",
    "    batch_df['PCA_Vectors'] = list(pca_vectors)\n",
    "    return batch_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_batch_generator(image_files, batch_size, show_progress=True):\n",
    "    total_batches = (len(image_files) + batch_size - 1) // batch_size\n",
    "    progress_bar = tqdm(total=total_batches, desc=\"Processing images\") if show_progress else None\n",
    "\n",
    "    for index in range(0, len(image_files), batch_size):\n",
    "        batch = image_files[index:index + batch_size]\n",
    "        details_list = [extract_image_details(image) for image in batch]\n",
    "        details_list = [features for features in details_list if features is not None]\n",
    "        image_vectors = np.array([features['Resized_Image_Vector'] for features in details_list])\n",
    "        df = pd.DataFrame(details_list)\n",
    "        yield df, image_vectors\n",
    "        if show_progress:\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    if show_progress:\n",
    "        progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79ebbefebbc4201b27268f4077e15f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing C:\\Users\\timsa\\Desktop\\sample_pictures\\test_2.bmp: cannot identify image file 'C:\\\\Users\\\\timsa\\\\Desktop\\\\sample_pictures\\\\test_2.bmp'\n",
      "Error processing C:\\Users\\timsa\\Desktop\\sample_pictures\\test_2.bmp: cannot identify image file 'C:\\\\Users\\\\timsa\\\\Desktop\\\\sample_pictures\\\\test_2.bmp'\n"
     ]
    }
   ],
   "source": [
    "# Execution of code\n",
    "\n",
    "total_images = len(image_paths)\n",
    "batch_size = 100\n",
    "desired_size = (60, 60)   # size which the images will be resized to\n",
    "n_components = 10 # the amount of features our iPCA will keep for every image\n",
    "\n",
    "generator = image_batch_generator(image_paths, batch_size, show_progress=True)   # gives back batch_df + image as 1d\n",
    "ipca = process_large_image_dataset(generator, total_images, batch_size, n_components) # needed to fit the iPCA \n",
    "\n",
    "# After fitting IPCA, transform all data\n",
    "for batch_df, image_vectors in image_batch_generator(image_paths, batch_size, show_progress=False):\n",
    "    transformed_batch_df = transform_image_features(batch_df, image_vectors, ipca)\n",
    "\n",
    "    \n",
    "    transformed_batch_df.head()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Resized_Image_Vector</th>\n",
       "      <th>PCA_Vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34b0bb62-1f7b-45a8-8fc4-eaedddb5757f</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\0031.png</td>\n",
       "      <td>[195, 187, 177, 188, 167, 162, 144, 123, 139, ...</td>\n",
       "      <td>[496.6541985933603, -888.0665161932402, -3756....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8c0dfbb5-bba4-409d-8b57-849ce8bde435</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\adam-bi...</td>\n",
       "      <td>[222, 212, 208, 224, 213, 207, 225, 216, 209, ...</td>\n",
       "      <td>[12632.571816986021, -259.16952814348303, 2069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e07de2bc-620f-4a07-b2b9-653b6c86f0b6</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\adrian-...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-11009.597883374357, -501.0693401087662, -502...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d332eb0a-e650-4c85-a5ae-cec91dfc3c8c</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "      <td>[98, 98, 94, 41, 48, 38, 20, 32, 32, 14, 26, 2...</td>\n",
       "      <td>[-3963.8594334778113, 2623.8053094494276, 1098...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47e15f53-ee2d-42ac-81c7-a4e302982c86</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "      <td>[55, 51, 61, 36, 27, 30, 110, 51, 32, 161, 113...</td>\n",
       "      <td>[-4741.879883035555, -2071.263536722551, 1369....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "0  34b0bb62-1f7b-45a8-8fc4-eaedddb5757f   \n",
       "1  8c0dfbb5-bba4-409d-8b57-849ce8bde435   \n",
       "2  e07de2bc-620f-4a07-b2b9-653b6c86f0b6   \n",
       "3  d332eb0a-e650-4c85-a5ae-cec91dfc3c8c   \n",
       "4  47e15f53-ee2d-42ac-81c7-a4e302982c86   \n",
       "\n",
       "                                           File_Path  \\\n",
       "0    C:\\Users\\timsa\\Desktop\\sample_pictures\\0031.png   \n",
       "1  C:\\Users\\timsa\\Desktop\\sample_pictures\\adam-bi...   \n",
       "2  C:\\Users\\timsa\\Desktop\\sample_pictures\\adrian-...   \n",
       "3  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...   \n",
       "4  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...   \n",
       "\n",
       "                                Resized_Image_Vector  \\\n",
       "0  [195, 187, 177, 188, 167, 162, 144, 123, 139, ...   \n",
       "1  [222, 212, 208, 224, 213, 207, 225, 216, 209, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [98, 98, 94, 41, 48, 38, 20, 32, 32, 14, 26, 2...   \n",
       "4  [55, 51, 61, 36, 27, 30, 110, 51, 32, 161, 113...   \n",
       "\n",
       "                                         PCA_Vectors  \n",
       "0  [496.6541985933603, -888.0665161932402, -3756....  \n",
       "1  [12632.571816986021, -259.16952814348303, 2069...  \n",
       "2  [-11009.597883374357, -501.0693401087662, -502...  \n",
       "3  [-3963.8594334778113, 2623.8053094494276, 1098...  \n",
       "4  [-4741.879883035555, -2071.263536722551, 1369....  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_batch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                    16\n",
       "unique                                                   16\n",
       "top       [496.6541985933603, -888.0665161932402, -3756....\n",
       "freq                                                      1\n",
       "Name: PCA_Vectors, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_batch_df[\"PCA_Vectors\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12632.57181699,  -259.16952814,  2069.72584842,   444.01229774,\n",
       "         481.85474691,   -62.15674047,   918.43916599,   427.64807317,\n",
       "         293.81656367,   -74.17618535])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_batch_df[\"PCA_Vectors\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
