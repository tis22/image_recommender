{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ExifTags\n",
    "import uuid\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "from scipy.spatial import distance \n",
    "from sklearn.metrics import pairwise_distances\n",
    "from numba import jit, prange\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193a95bb7c0b4bb8994567a5559f484d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Durchsuche Verzeichnisse:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl gefundener Bilder: 500\n",
      "Einige der gefundenen Bildpfade: ['D:\\\\data\\\\image_data\\\\coco2017_train\\\\train2017\\\\000000000034.jpg', 'D:\\\\data\\\\image_data\\\\coco2017_train\\\\train2017\\\\000000000049.jpg', 'D:\\\\data\\\\image_data\\\\coco2017_train\\\\train2017\\\\000000000071.jpg', 'D:\\\\data\\\\image_data\\\\coco2017_train\\\\train2017\\\\000000000078.jpg', 'D:\\\\data\\\\image_data\\\\coco2017_train\\\\train2017\\\\000000000081.jpg', 'D:\\\\data\\\\image_data\\\\coco2017_train\\\\train2017\\\\000000000089.jpg', 'D:\\\\data\\\\image_data\\\\coco2017_train\\\\train2017\\\\000000000208.jpg', 'D:\\\\data\\\\image_data\\\\coco2017_train\\\\train2017\\\\000000000241.jpg', 'D:\\\\data\\\\image_data\\\\coco2017_train\\\\train2017\\\\000000000247.jpg', 'D:\\\\data\\\\image_data\\\\coco2017_train\\\\train2017\\\\000000000283.jpg']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Es sind insgesamt 444670 Bilder, deshalb kann max_files gesetzt werden und tqdm läuft akkurat.\n",
    "Eine andere Möglichkeit die tqdm bar anzupassen gibt es nicht, weil die Bilder dynamisch geladen werden.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def find_image_files(root_dir, extensions=('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'), max_files=500):\n",
    "    image_files = []\n",
    "    # Initialisierung von tqdm außerhalb von os.walk, um die Anzahl der Dateien zu zählen\n",
    "    pbar = tqdm(total=max_files, desc='Durchsuche Verzeichnisse')\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(extensions):\n",
    "                image_files.append(os.path.join(subdir, file))\n",
    "                pbar.update(1)\n",
    "                if len(image_files) >= max_files:\n",
    "                    pbar.close()\n",
    "                    return image_files  # Beendet die Suche, wenn das Limit erreicht ist\n",
    "    pbar.close()  # Schließe den tqdm-Balken, wenn die Suche beendet ist\n",
    "    return image_files\n",
    "\n",
    "# Verwenden der Funktion, um Bildpfade aus dem 'data'-Verzeichnis zu sammeln\n",
    "image_paths = find_image_files(\"D:\\\\data\\\\image_data\")\n",
    "\n",
    "# Anzeigen der Anzahl der gefundenen Bilder und der ersten 10 Bildpfade zur Überprüfung\n",
    "print(f\"Anzahl gefundener Bilder: {len(image_paths)}\")\n",
    "if len(image_paths) > 10:\n",
    "    print(\"Einige der gefundenen Bildpfade:\", image_paths[:10])\n",
    "else:\n",
    "    print(\"Gefundene Bildpfade:\", image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizin the image into same Dimension, \n",
    "# image as vector\n",
    "# calculating distances     img with itself and others\n",
    "# image embeddings?\n",
    "# if pictures embedded, hamming distance might come handy\n",
    "# \n",
    "\n",
    "\n",
    "'''\n",
    "Using the JIT decorator to parallelize calculations\n",
    "extracting image details and saving them to a df\n",
    "processing the image vectors seperately because the Standardscaler which is crucial for PCA needs a batch of images\n",
    "________\n",
    "PCA_COMPONENTS need to find balance between reduced dimension and preserved variation in data - test with \n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#@jit(parallel=True)\n",
    "def calculate_avg_color_brightness(pixels):\n",
    "    \"\"\"\n",
    "    Calculates the average color and brightness of an image.\n",
    "    \n",
    "    Parameters:\n",
    "    pixels (list): List of pixel values in the image.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: The average color (RGB) and brightness of the image.\n",
    "    \"\"\"\n",
    "    avg_color = tuple(sum(col) // len(pixels) for col in zip(*pixels))\n",
    "    avg_brightness = sum(sum(pixel) for pixel in pixels) // (3 * len(pixels))\n",
    "    return avg_color, avg_brightness\n",
    "\n",
    "def extract_image_details(image_path):\n",
    "    \"\"\"\n",
    "    Extracts details from an image, including resizing, color values, brightness, resolution, DPI, metadata, and generates a unique ID.\n",
    "    \n",
    "    Parameters:\n",
    "    image_path (str): The file path of the image.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing image details and the resized image vector.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img = img.convert('RGB')  # Convert to RGB\n",
    "\n",
    "            # Resize image\n",
    "            img_cv = cv2.imread(image_path)\n",
    "            resized = cv2.resize(img_cv, desired_size)\n",
    "            img_as_1d = np.array(resized).flatten() #this could be parallelized\n",
    "\n",
    "\n",
    "            # Color values and brightness\n",
    "            pixels = list(img.getdata())\n",
    "            avg_color, avg_brightness = calculate_avg_color_brightness(pixels)\n",
    "\n",
    "\n",
    "            # Resolution and DPI\n",
    "            resolution = img.size  # (width, height)\n",
    "            dpi = img.info.get('dpi', (0, 0))\n",
    "\n",
    "\n",
    "            # Extract metadata\n",
    "            try:\n",
    "                exif_data = img._getexif()\n",
    "                metadata = {ExifTags.TAGS[k]: v for k, v in exif_data.items() if k in ExifTags.TAGS} if exif_data else {}\n",
    "            except AttributeError:\n",
    "                metadata = {}\n",
    "\n",
    "            # File details\n",
    "            file_size = os.path.getsize(image_path)\n",
    "            file_type = os.path.splitext(image_path)[1]\n",
    "\n",
    "            # UUID\n",
    "            unique_id = str(uuid.uuid4())\n",
    "\n",
    "        return {\n",
    "            'ID': unique_id,\n",
    "            'File_Path': image_path,\n",
    "            'Average_Color': avg_color,\n",
    "            'Brightness': avg_brightness,\n",
    "            'Resolution': resolution,\n",
    "            'DPI': dpi,\n",
    "            'File_Size': file_size,\n",
    "            'File_Type': file_type,\n",
    "            'Metadata': metadata,\n",
    "            'Resized_Image_Vector': img_as_1d\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_large_image_dataset(generator, total_images, batch_size, n_components):\n",
    "    \"\"\"\n",
    "    Processes a large image dataset using IncrementalPCA in batches.\n",
    "\n",
    "    Parameters:\n",
    "    generator (generator): Generator yielding batches of image data.\n",
    "    total_images (int): Total number of images in the dataset.\n",
    "    batch_size (int): Number of images to process in each batch.\n",
    "    n_components (int): Number of principal components to keep.\n",
    "\n",
    "    Returns:\n",
    "    IncrementalPCA: The fitted IncrementalPCA model.\n",
    "    \"\"\"\n",
    "    ipca = IncrementalPCA(n_components=n_components)\n",
    "    \n",
    "    for _ in range(0, total_images, batch_size):\n",
    "        batch_df, image_vectors = next(generator)\n",
    "        ipca.partial_fit(image_vectors)\n",
    "    \n",
    "    return ipca\n",
    "\n",
    "\n",
    "def transform_image_features(batch_df, image_vectors, ipca):\n",
    "    \"\"\"\n",
    "    Transforms image features using PCA.\n",
    "\n",
    "    Parameters:\n",
    "    batch_df (pd.DataFrame): The DataFrame containing batch image details.\n",
    "    image_vectors (np.array): The array of image vectors.\n",
    "    ipca (IncrementalPCA): The pre-fitted IncrementalPCA.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The updated DataFrame with PCA vectors added.\n",
    "    \"\"\"\n",
    "    pca_vectors = ipca.transform(image_vectors)\n",
    "    batch_df['PCA_Vectors'] = list(pca_vectors)\n",
    "    return batch_df\n",
    "\n",
    "def compute_and_store_pairwise_distances(df):\n",
    "    \"\"\"\n",
    "    Computes and stores pairwise distances between PCA vectors in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing image details and PCA vectors.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The updated DataFrame with pairwise distances added.\n",
    "    \"\"\"\n",
    "    pca_vectors = np.vstack(df['PCA_Vectors'].values)\n",
    "    \n",
    "    distances = pairwise_distances(pca_vectors, metric='euclidean')\n",
    "    \n",
    "    df['Pairwise_Distances'] = distances.tolist()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_batch_generator(image_files, batch_size, show_progress=True):\n",
    "    total_batches = (len(image_files) + batch_size - 1) // batch_size\n",
    "    progress_bar = tqdm(total=total_batches, desc=\"Processing images\") if show_progress else None\n",
    "\n",
    "    for index in range(0, len(image_files), batch_size):\n",
    "        batch = image_files[index:index + batch_size]\n",
    "        details_list = [extract_image_details(image) for image in batch]\n",
    "        details_list = [features for features in details_list if features is not None]\n",
    "        image_vectors = np.array([features['Resized_Image_Vector'] for features in details_list])\n",
    "        df = pd.DataFrame(details_list)\n",
    "        yield df, image_vectors\n",
    "        if show_progress:\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    if show_progress:\n",
    "        progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae666b149464025a44f2aa0672e6474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nThis outputs the metadata batchwise and overwrites it.\\nYou need extract the details from ___transformed_batch_df___ into SQLite.\\nIn summary, extracted details by now are:\\n\\nID\\nFile_Path\\nAverage_Color\\nBrightness\\nResolution\\nDPI\\nFile_Size\\nFile_Type\\nMetadata\\nResized_Image_Vector\\nPCA_Vectors\\nPairwise_Distances\\n\\nNOTE \"Metadata\" might be empty\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execution of code\n",
    "\n",
    "total_images = len(image_paths)\n",
    "batch_size = 100\n",
    "desired_size = (60, 60)   # size which the images will be resized to\n",
    "n_components = 10 # the amount of features our iPCA will keep for every image\n",
    "\n",
    "generator = image_batch_generator(image_paths, batch_size, show_progress=True)   # gives back batch_df + image as 1d\n",
    "ipca = process_large_image_dataset(generator, total_images, batch_size, n_components) # needed to fit the iPCA \n",
    "\n",
    "# After fitting IPCA, transform all data\n",
    "for batch_df, image_vectors in image_batch_generator(image_paths, batch_size, show_progress=False):\n",
    "    transformed_batch_df = transform_image_features(batch_df, image_vectors, ipca)\n",
    "    transformed_batch_df = compute_and_store_pairwise_distances(transformed_batch_df)\n",
    "\n",
    "    \n",
    "    transformed_batch_df.head()   \n",
    "\n",
    "'''\n",
    "This outputs the metadata batchwise and overwrites it.\n",
    "You need extract the details from ___transformed_batch_df___ into SQLite.\n",
    "In summary, extracted details by now are:\n",
    "\n",
    "ID\n",
    "File_Path\n",
    "Average_Color\n",
    "Brightness\n",
    "Resolution\n",
    "DPI\n",
    "File_Size\n",
    "File_Type\n",
    "Metadata\n",
    "Resized_Image_Vector\n",
    "PCA_Vectors\n",
    "Pairwise_Distances\n",
    "\n",
    "NOTE \"Metadata\" might be empty\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Average_Color</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>DPI</th>\n",
       "      <th>File_Size</th>\n",
       "      <th>File_Type</th>\n",
       "      <th>Metadata</th>\n",
       "      <th>Resized_Image_Vector</th>\n",
       "      <th>PCA_Vectors</th>\n",
       "      <th>Pairwise_Distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f3987f73-d46e-4d0d-9945-ca03d710bca6</td>\n",
       "      <td>D:\\data\\image_data\\coco2017_train\\train2017\\00...</td>\n",
       "      <td>(71, 67, 64)</td>\n",
       "      <td>67</td>\n",
       "      <td>(640, 562)</td>\n",
       "      <td>(72, 72)</td>\n",
       "      <td>111422</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>{}</td>\n",
       "      <td>[18, 18, 56, 26, 20, 70, 83, 85, 109, 110, 109...</td>\n",
       "      <td>[-4512.473313312545, -1471.4342959269018, -138...</td>\n",
       "      <td>[0.0, 6635.948449420372, 5687.580701034129, 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>427f5baf-a43f-434a-9db2-02809a268d59</td>\n",
       "      <td>D:\\data\\image_data\\coco2017_train\\train2017\\00...</td>\n",
       "      <td>(139, 121, 66)</td>\n",
       "      <td>109</td>\n",
       "      <td>(640, 480)</td>\n",
       "      <td>(72, 72)</td>\n",
       "      <td>95569</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>{}</td>\n",
       "      <td>[96, 184, 224, 113, 193, 224, 132, 206, 228, 1...</td>\n",
       "      <td>[-835.2963255805532, -942.5905031221771, 2307....</td>\n",
       "      <td>[6635.948449420372, 0.0, 5259.761316618222, 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0d74e760-1cb3-49b2-a48e-3a177cbf355a</td>\n",
       "      <td>D:\\data\\image_data\\coco2017_train\\train2017\\00...</td>\n",
       "      <td>(103, 109, 85)</td>\n",
       "      <td>99</td>\n",
       "      <td>(427, 640)</td>\n",
       "      <td>(72, 72)</td>\n",
       "      <td>268466</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>{}</td>\n",
       "      <td>[197, 223, 217, 199, 183, 171, 195, 203, 198, ...</td>\n",
       "      <td>[-501.49420655028104, -4558.463264780337, -266...</td>\n",
       "      <td>[5687.580701034129, 5259.761316618222, 0.0, 55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75020130-1650-4e54-b2d9-9669bd7eadd5</td>\n",
       "      <td>D:\\data\\image_data\\coco2017_train\\train2017\\00...</td>\n",
       "      <td>(89, 88, 88)</td>\n",
       "      <td>88</td>\n",
       "      <td>(640, 480)</td>\n",
       "      <td>(72, 72)</td>\n",
       "      <td>161052</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>{}</td>\n",
       "      <td>[26, 25, 25, 52, 60, 65, 48, 61, 58, 186, 175,...</td>\n",
       "      <td>[-2304.2186613479794, -42.842444229631994, -14...</td>\n",
       "      <td>[3214.4082551706397, 5820.707502516365, 5526.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8a22ede1-051c-4b9a-9e7d-4dcac3b7bf50</td>\n",
       "      <td>D:\\data\\image_data\\coco2017_train\\train2017\\00...</td>\n",
       "      <td>(171, 171, 167)</td>\n",
       "      <td>169</td>\n",
       "      <td>(640, 411)</td>\n",
       "      <td>(72, 72)</td>\n",
       "      <td>97074</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>{}</td>\n",
       "      <td>[159, 159, 159, 156, 156, 156, 157, 157, 157, ...</td>\n",
       "      <td>[5591.430876170691, 1999.325915828613, 196.939...</td>\n",
       "      <td>[11004.13469208075, 8007.076008069452, 9258.61...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "0  f3987f73-d46e-4d0d-9945-ca03d710bca6   \n",
       "1  427f5baf-a43f-434a-9db2-02809a268d59   \n",
       "2  0d74e760-1cb3-49b2-a48e-3a177cbf355a   \n",
       "3  75020130-1650-4e54-b2d9-9669bd7eadd5   \n",
       "4  8a22ede1-051c-4b9a-9e7d-4dcac3b7bf50   \n",
       "\n",
       "                                           File_Path    Average_Color  \\\n",
       "0  D:\\data\\image_data\\coco2017_train\\train2017\\00...     (71, 67, 64)   \n",
       "1  D:\\data\\image_data\\coco2017_train\\train2017\\00...   (139, 121, 66)   \n",
       "2  D:\\data\\image_data\\coco2017_train\\train2017\\00...   (103, 109, 85)   \n",
       "3  D:\\data\\image_data\\coco2017_train\\train2017\\00...     (89, 88, 88)   \n",
       "4  D:\\data\\image_data\\coco2017_train\\train2017\\00...  (171, 171, 167)   \n",
       "\n",
       "   Brightness  Resolution       DPI  File_Size File_Type Metadata  \\\n",
       "0          67  (640, 562)  (72, 72)     111422      .jpg       {}   \n",
       "1         109  (640, 480)  (72, 72)      95569      .jpg       {}   \n",
       "2          99  (427, 640)  (72, 72)     268466      .jpg       {}   \n",
       "3          88  (640, 480)  (72, 72)     161052      .jpg       {}   \n",
       "4         169  (640, 411)  (72, 72)      97074      .jpg       {}   \n",
       "\n",
       "                                Resized_Image_Vector  \\\n",
       "0  [18, 18, 56, 26, 20, 70, 83, 85, 109, 110, 109...   \n",
       "1  [96, 184, 224, 113, 193, 224, 132, 206, 228, 1...   \n",
       "2  [197, 223, 217, 199, 183, 171, 195, 203, 198, ...   \n",
       "3  [26, 25, 25, 52, 60, 65, 48, 61, 58, 186, 175,...   \n",
       "4  [159, 159, 159, 156, 156, 156, 157, 157, 157, ...   \n",
       "\n",
       "                                         PCA_Vectors  \\\n",
       "0  [-4512.473313312545, -1471.4342959269018, -138...   \n",
       "1  [-835.2963255805532, -942.5905031221771, 2307....   \n",
       "2  [-501.49420655028104, -4558.463264780337, -266...   \n",
       "3  [-2304.2186613479794, -42.842444229631994, -14...   \n",
       "4  [5591.430876170691, 1999.325915828613, 196.939...   \n",
       "\n",
       "                                  Pairwise_Distances  \n",
       "0  [0.0, 6635.948449420372, 5687.580701034129, 32...  \n",
       "1  [6635.948449420372, 0.0, 5259.761316618222, 58...  \n",
       "2  [5687.580701034129, 5259.761316618222, 0.0, 55...  \n",
       "3  [3214.4082551706397, 5820.707502516365, 5526.4...  \n",
       "4  [11004.13469208075, 8007.076008069452, 9258.61...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_batch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                   100\n",
       "unique                                                  100\n",
       "top       [-4512.473313312545, -1471.4342959269018, -138...\n",
       "freq                                                      1\n",
       "Name: PCA_Vectors, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_batch_df[\"PCA_Vectors\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
