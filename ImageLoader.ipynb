{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ExifTags\n",
    "import cv2\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import pairwise\n",
    "import time\n",
    "import sqlite3\n",
    "import pickle\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import umap\n",
    "import joblib\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrival Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_files(root_dir, extensions=(\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".tif\")):\n",
    "    \"\"\"\n",
    "    Load all image paths and get the total number of images,\n",
    "    we can't use tqdm here, because we have to determine the number of images first.\n",
    "    \"\"\"\n",
    "    image_files = []\n",
    "\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(extensions):\n",
    "                image_files.append(os.path.join(subdir, file))\n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement functions\n",
    "\n",
    "\n",
    "def image_rgb_calculation(image):\n",
    "    # OpenCV uses BGR color space, we have to convert it to the RGB color space\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Calculate the histogram\n",
    "    hist = cv2.calcHist([rgb_image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "\n",
    "    # Normalize the histogram so that histograms of different images (different sizes, resolutions) are comparable\n",
    "    hist = cv2.normalize(hist, hist)\n",
    "    hist = hist.flatten()\n",
    "    return hist\n",
    "\n",
    "\n",
    "def image_hsv_calculation(image):\n",
    "    # OpenCV uses BGR color space, we have to convert it to the RGB color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Calculate the histogram (bin-sizes = 8, values from 0-255)\n",
    "    hist = cv2.calcHist([hsv_image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "\n",
    "    # Normalize the histogram so that histograms of different images (different sizes, resolutions) are comparable\n",
    "    hist = cv2.normalize(hist, hist)\n",
    "    hist = hist.flatten()\n",
    "    return hist\n",
    "\n",
    "\n",
    "def load_embedding_model():\n",
    "    global model, preprocess\n",
    "    # Load the efficientnet_v2_s model\n",
    "    model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)\n",
    "\n",
    "    # Remove last layer (classificator), because we only need the features\n",
    "    model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "    model.eval()\n",
    "\n",
    "    # Define preprocessing transformations\n",
    "    preprocess = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def model_embeddings_calculation(image):\n",
    "    global model, preprocess\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = model(input_batch)\n",
    "    features = torch.flatten(features, 1)\n",
    "\n",
    "    return features.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_details(image_id, path, resize_size):\n",
    "    try:\n",
    "        image = cv2.imread(path)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, resize_size)\n",
    "            rgb_histogram = image_rgb_calculation(image)\n",
    "            hsv_histogram = image_hsv_calculation(image)\n",
    "            model_embedding = model_embeddings_calculation(image)\n",
    "\n",
    "            ### several more informations ###\n",
    "\n",
    "            # Convert to RGB\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Calculate average color and brightness\n",
    "            avg_color = np.mean(image_rgb, axis=(0, 1)).tolist()\n",
    "            avg_brightness = np.mean(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "            # Convert to HSV and calculate average HSV\n",
    "            image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            avg_hsv = np.mean(image_hsv, axis=(0, 1)).tolist()\n",
    "\n",
    "            # File details\n",
    "            file_size = os.path.getsize(path)\n",
    "            file_type = os.path.splitext(path)[1]\n",
    "\n",
    "            with Image.open(path) as img:\n",
    "                # Resolution and DPI\n",
    "                resolution = img.size  # (width, height)\n",
    "                dpi = img.info.get(\"dpi\", (0, 0))\n",
    "\n",
    "                # Extract metadata\n",
    "                try:\n",
    "                    exif_data = img._getexif()\n",
    "                    metadata = {ExifTags.TAGS.get(k, k): v for k, v in exif_data.items()} if exif_data else {}\n",
    "                except AttributeError:\n",
    "                    metadata = {}\n",
    "\n",
    "            #################################\n",
    "\n",
    "            return {\n",
    "                \"ID\": image_id,\n",
    "                \"Path\": path,\n",
    "                \"RGB_Histogram\": rgb_histogram,\n",
    "                \"HSV_Histogram\": hsv_histogram,\n",
    "                \"Model_Embedding\": model_embedding,\n",
    "                \"Average_Color\": avg_color,\n",
    "                \"Brightness\": avg_brightness,\n",
    "                \"Average_HSV\": avg_hsv,\n",
    "                \"Resolution\": resolution,\n",
    "                \"DPI\": dpi,\n",
    "                \"File_Size\": file_size,\n",
    "                \"File_Type\": file_type,\n",
    "                \"Metadata\": metadata,\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            print(f\"Image at path {path} is None.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed processing {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_checkpoint():\n",
    "    if not os.path.exists(\"checkpoint.pkl\"):\n",
    "        return 0, [], [], [], [], []\n",
    "\n",
    "    with open(\"checkpoint.pkl\", \"rb\") as f:\n",
    "        batch_index, paths, rgb_hists, hsv_hists, embeddings, other_data = pickle.load(f)\n",
    "        print(f\"Loaded checkpoint.\\nStarting from path with ID: {batch_index + 1}\")\n",
    "\n",
    "    return batch_index, paths, rgb_hists, hsv_hists, embeddings, other_data\n",
    "\n",
    "\n",
    "def image_batch_generator(image_files, batch_size, resize_size, start_index=0, show_progress=True):\n",
    "    total_batches = (\n",
    "        len(image_files) - start_index + batch_size - 1\n",
    "    ) // batch_size  # - start_index to display remaining batches correctly\n",
    "    progress_bar = tqdm(total=total_batches, desc=\"Processing images\") if show_progress else None\n",
    "\n",
    "    current_id = start_index + 1\n",
    "\n",
    "    for index in range(start_index, len(image_files), batch_size):\n",
    "        batch = image_files[index : index + batch_size]\n",
    "        details_list = []\n",
    "\n",
    "        for i, path in enumerate(batch):\n",
    "            features = extract_image_details(current_id, path, resize_size)\n",
    "            if features is not None:\n",
    "                details_list.append(features)\n",
    "                current_id += 1  # Increase only if an image has been successfully read\n",
    "\n",
    "        df = pd.DataFrame(details_list)\n",
    "        yield df, index + batch_size\n",
    "        if show_progress:\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    if show_progress:\n",
    "        progress_bar.close()\n",
    "\n",
    "\n",
    "def main_load_images(batch_size, desired_size):\n",
    "    # Load checkpoint\n",
    "    start_index, paths, rgb_hists, hsv_hists, embeddings, other_data = load_checkpoint()\n",
    "\n",
    "    image_paths = find_image_files(r\"C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\\extra_collection\\city\")\n",
    "\n",
    "    load_embedding_model()\n",
    "\n",
    "    for df, batch_index in image_batch_generator(\n",
    "        image_paths, batch_size, desired_size, start_index=start_index, show_progress=True\n",
    "    ):\n",
    "        paths.extend(df[[\"ID\", \"Path\"]].values.tolist())\n",
    "        rgb_hists.extend(df[[\"ID\", \"RGB_Histogram\"]].values.tolist())\n",
    "        hsv_hists.extend(df[[\"ID\", \"HSV_Histogram\"]].values.tolist())\n",
    "        embeddings.extend(df[[\"ID\", \"Model_Embedding\"]].values.tolist())\n",
    "        other_data.extend(\n",
    "            df.drop(columns=[\"Path\", \"RGB_Histogram\", \"HSV_Histogram\", \"Model_Embedding\"]).values.tolist()\n",
    "        )\n",
    "\n",
    "        # Save checkpoint, overrides old one and appends new data\n",
    "        with open(\"checkpoint.pkl\", \"wb\") as f:\n",
    "            pickle.dump((batch_index, paths, rgb_hists, hsv_hists, embeddings, other_data), f)\n",
    "\n",
    "    # Save results\n",
    "    df_paths = pd.DataFrame(paths, columns=[\"ID\", \"Path\"])\n",
    "    df_rgb = pd.DataFrame(rgb_hists, columns=[\"ID\", \"Histogram\"])\n",
    "    df_hsv = pd.DataFrame(hsv_hists, columns=[\"ID\", \"Histogram\"])\n",
    "    df_embeddings = pd.DataFrame(embeddings, columns=[\"ID\", \"Embedding\"])\n",
    "    df_other_data = pd.DataFrame(\n",
    "        other_data,\n",
    "        columns=[\n",
    "            \"ID\",\n",
    "            \"Average_Color\",\n",
    "            \"Brightness\",\n",
    "            \"Average_HSV\",\n",
    "            \"Resolution\",\n",
    "            \"DPI\",\n",
    "            \"File_Size\",\n",
    "            \"File_Type\",\n",
    "            \"Metadata\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    df_paths.to_pickle(\"Path.pkl\")\n",
    "    df_rgb.to_pickle(\"RGB_Hist.pkl\")\n",
    "    df_hsv.to_pickle(\"HSV_Hist.pkl\")\n",
    "    df_embeddings.to_pickle(\"Embedding.pkl\")\n",
    "    df_other_data.to_pickle(\"Other_data.pkl\")\n",
    "\n",
    "    # Checkpoint can be removed after program was successful\n",
    "    if os.path.exists(\"checkpoint.pkl\"):\n",
    "        os.remove(\"checkpoint.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Execute\n",
    "batch_size = 1000\n",
    "desired_size = (224, 224)\n",
    "main_load_images(batch_size, desired_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database():\n",
    "    # Check if the folder 'databases' does not exist / create it\n",
    "    if not os.path.exists(\"database\"):\n",
    "        os.makedirs(\"database\")\n",
    "\n",
    "    conn = sqlite3.connect(\"database/bd_database.db\")\n",
    "    curs = conn.cursor()\n",
    "\n",
    "    curs.execute(\n",
    "        \"\"\"CREATE TABLE IF NOT EXISTS image_paths \n",
    "                    (ID INTEGER PRIMARY KEY,\n",
    "                    Path text);\"\"\"\n",
    "    )\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_db(df, conn):\n",
    "    curs = conn.cursor()\n",
    "    for file_path in df[\"Path\"]:\n",
    "        curs.execute(\"\"\"INSERT OR IGNORE INTO image_paths (Path) VALUES (?);\"\"\", (file_path,))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = pd.read_pickle(\"Path.pkl\")\n",
    "connection = conn = sqlite3.connect(\"database/bd_database.db\")\n",
    "\n",
    "# Change drive letter (if necessary)\n",
    "# It could be (depending on the respective windows configuration)\n",
    "# that the saved path is not the actual path on another windows system\n",
    "old_drive_letter = \"D\"\n",
    "new_drive_letter = \"F\"\n",
    "path_df[\"Path\"] = path_df[\"Path\"].apply(lambda path: path.replace(f\"{old_drive_letter}:\", f\"{new_drive_letter}:\"))\n",
    "\n",
    "save_to_db(path_df, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickles():\n",
    "    rgb_df = pd.read_pickle(\"RGB_Hist.pkl\")\n",
    "    hsv_df = pd.read_pickle(\"HSV_Hist.pkl\")\n",
    "    embedding_df = pd.read_pickle(\"Embedding.pkl\")\n",
    "    path_df = pd.read_pickle(\"Path.pkl\")\n",
    "    other_data_df = pd.read_pickle(\"Other_data.pkl\")\n",
    "\n",
    "    return rgb_df, hsv_df, embedding_df, path_df, other_data_df\n",
    "\n",
    "\n",
    "def find_similar_ids(measurement, similarity, df_input, best_n):\n",
    "    similarity_functions = {\"euclidean\": \"euclidean\", \"manhattan\": \"cityblock\", \"cosine\": \"cosine\"}\n",
    "\n",
    "    histogram_columns = {\"RGB\": \"RGB_Histogram\", \"HSV\": \"HSV_Histogram\", \"Embedding\": \"Model_Embedding\"}\n",
    "\n",
    "    dataframes = {\"RGB\": rgb_df, \"HSV\": hsv_df, \"Embedding\": embedding_df}\n",
    "\n",
    "    # Create new input-df with the needed column\n",
    "    df_input_selected = df_input[[\"ID\", histogram_columns[measurement]]]\n",
    "\n",
    "    # Select needed comparison-df\n",
    "    target_df = dataframes[measurement]\n",
    "\n",
    "    # Select comparison function\n",
    "    similarity_function = similarity_functions[similarity]\n",
    "\n",
    "    similarity_ids = calculate_mean_similarity(df_input_selected, target_df, similarity_function, best_n)\n",
    "    return similarity_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "def get_result_paths(curs, similarity_results):\n",
    "    result_paths = []\n",
    "    for image_id in similarity_results:\n",
    "        curs.execute(\n",
    "            \"\"\"SELECT path\n",
    "                        FROM image_paths\n",
    "                        WHERE ID == (?);\"\"\",\n",
    "            (image_id,),\n",
    "        )\n",
    "        results = curs.fetchall()\n",
    "\n",
    "        # If there are results save only the path (otherwise the output would be lists with tuples)\n",
    "        if results:\n",
    "            result_paths.append(results[0][0])\n",
    "    return result_paths\n",
    "\n",
    "\n",
    "def print_images(input_images, result_paths, similarities, best_n):\n",
    "    input_images_number = len(input_images)\n",
    "    max_images = max(input_images_number, best_n)\n",
    "    figsize = (20, 5)\n",
    "\n",
    "    # Subplots to plot input(s) and results\n",
    "    # First row\n",
    "    fig, axes = plt.subplots(1, max_images, figsize=figsize)\n",
    "\n",
    "    for i in range(input_images_number):\n",
    "        image = Image.open(input_images.iloc[i, 1])\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].set_title(f\"Input: {i+1}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Fill remaining axes with empty plots if needed\n",
    "    for i in range(input_images_number, max_images):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Second row\n",
    "    fig, axes = plt.subplots(1, max_images, figsize=figsize)\n",
    "\n",
    "    for i in range(best_n):\n",
    "        image = Image.open(result_paths[i])\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].set_title(f\"Result ID: {similarities[i]}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Fill remaining axes with empty plots if needed\n",
    "    for i in range(best_n, max_images):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean if more than one input image or just the similarity\n",
    "# Creates a new df with the ID, similarity value per input image (and the mean)\n",
    "\n",
    "\n",
    "def calculate_mean_similarity(df_input_measurements, df_comparison_data, similarity_function, best_n):\n",
    "    input_ids = df_input_measurements[\"ID\"].values\n",
    "    comparison_ids = df_comparison_data[\"ID\"].values\n",
    "\n",
    "    # Extract the histogram columns by dropping the 'ID' column\n",
    "    input_histogram_column = df_input_measurements.drop(columns=[\"ID\"]).columns[0]\n",
    "    comparison_histogram_column = df_comparison_data.drop(columns=[\"ID\"]).columns[0]\n",
    "\n",
    "    # Convert histogram columns to numeric arrays\n",
    "    input_features = np.vstack(df_input_measurements[input_histogram_column].values)\n",
    "    comparison_features = np.vstack(df_comparison_data[comparison_histogram_column].values)\n",
    "\n",
    "    # Calculate similarity for each pair (rows)\n",
    "    similarity_matrix = cdist(comparison_features, input_features, metric=similarity_function)\n",
    "\n",
    "    similarity_results = pd.DataFrame(similarity_matrix, columns=input_ids)\n",
    "\n",
    "    # Add ID column and order columns\n",
    "    similarity_results[\"ID\"] = df_comparison_data[\"ID\"]\n",
    "    similarity_results = similarity_results[[\"ID\"] + list(input_ids)]\n",
    "\n",
    "    # print(similarity_results)\n",
    "\n",
    "    # Calculate mean\n",
    "    if len(input_ids) > 1:\n",
    "        similarity_results[\"Mean\"] = similarity_results.drop(columns=[\"ID\"]).mean(axis=1)\n",
    "        sorted_results = similarity_results.sort_values(by=\"Mean\", ascending=True)\n",
    "        # print(sorted_results)\n",
    "    else:\n",
    "        sorted_results = similarity_results.sort_values(by=input_ids[0], ascending=True)\n",
    "        # print(sorted_results)\n",
    "\n",
    "    # print(sorted_results)\n",
    "\n",
    "    # Return just a list with the best n similarities\n",
    "    best_ids = sorted_results.head(best_n)[\"ID\"].tolist()\n",
    "    return best_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same image is: cheng-feng-psdV2Rl-GvU-unsplash.jpg\n",
    "\n",
    "\n",
    "def main_finding_similarities(input_images_number, measurement, similarity, best_n):\n",
    "    global rgb_df, hsv_df, embedding_df, path_df, other_data_df\n",
    "\n",
    "    # Load pickles (doing this outside is better for perform the main more than one time)\n",
    "    # rgb_df, hsv_df, embedding_df, path_df, other_data_df = load_pickles()\n",
    "\n",
    "    specific_image_path = [r\"C:\\Users\\timsa\\Desktop\\sample_pictures\\testing\\test_image_1.jpg\"]\n",
    "\n",
    "    all_image_paths = [\n",
    "        r\"C:\\Users\\timsa\\Desktop\\sample_pictures\\testing\\test_image_1.jpg\",\n",
    "        r\"C:\\Users\\timsa\\Desktop\\sample_pictures\\testing\\test_image_2.jpg\",\n",
    "        r\"C:\\Users\\timsa\\Desktop\\sample_pictures\\testing\\test_image_3.jpg\",\n",
    "        r\"C:\\Users\\timsa\\Desktop\\sample_pictures\\testing\\test_image_4.jpg\",\n",
    "        r\"C:\\Users\\timsa\\Desktop\\sample_pictures\\testing\\test_image_5.jpg\",\n",
    "        r\"C:\\Users\\timsa\\Desktop\\sample_pictures\\testing\\test_image_6.jpg\",\n",
    "    ]\n",
    "\n",
    "    # Decide which image(s)\n",
    "    if input_images_number == 1:\n",
    "        input_images = specific_image_path\n",
    "    else:\n",
    "        input_images = all_image_paths[:input_images_number]\n",
    "\n",
    "    # print(input_images)\n",
    "    resize_size = (224, 224)\n",
    "    max_id = path_df[\"ID\"].max()\n",
    "\n",
    "    load_embedding_model()\n",
    "\n",
    "    current_id = max_id + 1  # Start ID from the maximum existing ID + 1\n",
    "    details_list = []\n",
    "\n",
    "    for i, path in enumerate(input_images):\n",
    "        features = extract_image_details(current_id, path, resize_size)\n",
    "        if features is not None:\n",
    "            details_list.append(features)\n",
    "            current_id += 1  # Increase only if an image has been successfully read\n",
    "\n",
    "    df_input = pd.DataFrame(details_list)\n",
    "    # print(df_input)\n",
    "\n",
    "    id_list = find_similar_ids(measurement, similarity, df_input, best_n)\n",
    "    # print(id_list)\n",
    "\n",
    "    conn = sqlite3.connect(\"database/bd_database.db\")\n",
    "    curs = conn.cursor()\n",
    "\n",
    "    result_paths_list = get_result_paths(curs, id_list)\n",
    "    # print(result_paths_list)\n",
    "\n",
    "    print_images(df_input, result_paths_list, id_list, best_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.31 s\n",
      "Wall time: 7.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global rgb_df, hsv_df, embedding_df, path_df, other_data_df\n",
    "\n",
    "# Load pickles\n",
    "rgb_df, hsv_df, embedding_df, path_df, other_data_df = load_pickles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "main_finding_similarities(1, \"RGB\", \"euclidean\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required because removing entries with 'none' (during extraction) sometimes causes IDs to be missing\n",
    "def correct_data():\n",
    "    rgb_df, hsv_df, embedding_df, path_df, other_data_df = load_pickles()\n",
    "\n",
    "    dataframes = [\n",
    "        (rgb_df, \"RGB_Hist.pkl\"),\n",
    "        (hsv_df, \"HSV_Hist.pkl\"),\n",
    "        (embedding_df, \"Embedding.pkl\"),\n",
    "        (path_df, \"Path.pkl\"),\n",
    "        (other_data_df, \"Other_data.pkl\"),\n",
    "    ]\n",
    "\n",
    "    mismatch_found = False\n",
    "\n",
    "    # Corrects mismatches from the mismatch-position until all mismatches are gone\n",
    "    for df, filename in dataframes:\n",
    "        corrected = False\n",
    "        while True:\n",
    "            # IDs are index + 1 always\n",
    "            expected_ids = df.index + 1\n",
    "\n",
    "            mismatch_index = (df[\"ID\"] != expected_ids).idxmax()\n",
    "\n",
    "            # Decide if there was a mismatch\n",
    "            if df.loc[mismatch_index, \"ID\"] == expected_ids[mismatch_index]:\n",
    "                if corrected:\n",
    "                    print(f\"Corrected: {filename}\")\n",
    "\n",
    "                    # Save only if corrections were made\n",
    "                    with open(filename, \"wb\") as f:\n",
    "                        pickle.dump(df, f)\n",
    "                    print(f\"Overwritten: {filename}\\n\")\n",
    "                    first_mismatch_found = True\n",
    "                else:\n",
    "                    print(f\"No mismatch: {filename}\")\n",
    "\n",
    "                break\n",
    "\n",
    "            # Reduce all IDs - 1 beginning from the mismatch\n",
    "            df.loc[mismatch_index:, \"ID\"] -= 1\n",
    "            corrected = True\n",
    "\n",
    "        # If no mismatch was found in the first file, exit the loop\n",
    "        if not corrected and not mismatch_found:\n",
    "            print(f\"No mismatch found in {filename}. Skipping remaining files.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected: RGB_Hist.pkl\n",
      "Overwritten: RGB_Hist.pkl\n",
      "\n",
      "Corrected: HSV_Hist.pkl\n",
      "Overwritten: HSV_Hist.pkl\n",
      "\n",
      "Corrected: Embedding.pkl\n",
      "Overwritten: Embedding.pkl\n",
      "\n",
      "Corrected: Path.pkl\n",
      "Overwritten: Path.pkl\n",
      "\n",
      "Corrected: Other_data.pkl\n",
      "Overwritten: Other_data.pkl\n",
      "\n",
      "CPU times: total: 2min 37s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "correct_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_data = pd.read_pickle(\"Embedding.pkl\")\n",
    "right_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensionality(df_to_reduce, algorithm, dimensions=2):\n",
    "    if algorithm == \"tsne\":\n",
    "        tsne = TSNE(n_components=dimensions)\n",
    "        reduced_data = tsne.fit_transform(df_to_reduce)\n",
    "\n",
    "    elif algorithm == \"umap\":\n",
    "        umap_model = umap.UMAP(n_components=dimensions)\n",
    "        reduced_data = umap_model.fit_transform(df_to_reduce)\n",
    "\n",
    "    else:\n",
    "        pca = PCA(n_components=dimensions)\n",
    "        reduced_data = pca.fit_transform(df_to_reduce)\n",
    "\n",
    "    return reduced_data\n",
    "\n",
    "\n",
    "def save_dimensionality_results(df, algorithm_name):\n",
    "    np.save(f\"{algorithm_name}_results.npy\", df)\n",
    "\n",
    "\n",
    "def create_clusters(\n",
    "    df_to_reduce,\n",
    "    cluster_amount=100,\n",
    "):\n",
    "    kmeans = KMeans(n_clusters=cluster_amount)\n",
    "    labels = kmeans.fit_predict(df_to_reduce)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def plot_dimensionality_reduction(algorithm_data, labels=None, output_file=None):\n",
    "    # Create empty lables to plot if labels=None\n",
    "    if labels is None:\n",
    "        labels = np.array([\"\"] * len(algorithm_data))\n",
    "\n",
    "    num_dims = algorithm_data.shape[1]\n",
    "\n",
    "    # Load dataframe to get IDs\n",
    "    df_embedding_ids = pd.read_pickle(\"Embedding.pkl\")\n",
    "    ids = df_embedding_ids[\"ID\"].values\n",
    "\n",
    "    # Decide 2D or 3D plot according to shape of algorithm_data (results)\n",
    "    if num_dims == 2:\n",
    "        fig = px.scatter(\n",
    "            x=algorithm_data[:, 0],\n",
    "            y=algorithm_data[:, 1],\n",
    "            color=labels.astype(str),\n",
    "            hover_name=ids,\n",
    "            labels={\"x\": \"Dim1\", \"y\": \"Dim2\"},\n",
    "            title=\"2D Plot\",\n",
    "        )\n",
    "\n",
    "        if output_file is not None:\n",
    "            fig.write_html(output_file)\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    else:\n",
    "        fig = px.scatter_3d(\n",
    "            x=algorithm_data[:, 0],\n",
    "            y=algorithm_data[:, 1],\n",
    "            z=algorithm_data[:, 2],\n",
    "            color=labels.astype(str),\n",
    "            hover_name=ids,\n",
    "            labels={\"x\": \"Dim1\", \"y\": \"Dim2\", \"z\": \"Dim3\"},\n",
    "            title=\"3D Plot\",\n",
    "        )\n",
    "        fig.update_traces(marker=dict(size=3, opacity=0.6))\n",
    "        fig.update_layout(margin=dict(l=0, r=0, b=0, t=40))\n",
    "\n",
    "        if output_file is not None:\n",
    "            fig.write_html(output_file)\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "def plot_selected_images(id_list):\n",
    "    conn = sqlite3.connect(\"database/bd_database.db\")\n",
    "    curs = conn.cursor()\n",
    "\n",
    "    result_paths_list = get_result_paths(curs, id_list)\n",
    "    fig, axes = plt.subplots(1, len(id_list), figsize=(20, 5))\n",
    "\n",
    "    for i in range(len(id_list)):\n",
    "        if i < len(id_list):\n",
    "            image = Image.open(result_paths_list[i])\n",
    "            axes[i].imshow(image)\n",
    "            axes[i].set_title(f\"ID: {id_list[i]}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing and plotting\n",
    "# df_from_pickle = pd.read_pickle(\"Embedding.pkl\")\n",
    "# df_to_reduce = np.vstack(df_from_pickle['Embedding'].values)\n",
    "# print(len(df_to_reduce))\n",
    "# print(len(df_to_reduce[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# reduced_data = reduce_dimensionality(df_to_reduce, \"tsne\", 2)\n",
    "# save_dimensionality_results(reduced_data, \"tsne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# clusters = create_clusters(df_to_reduce, 100)\n",
    "# save_dimensionality_results(clusters, \"kmeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create clusters based on tsne-results\n",
    "# %%time\n",
    "# clusters = create_clusters(dimensions_tsne, 100)\n",
    "# save_dimensionality_results(clusters, \"tsne_kmeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loading and plotting results\n",
    "dimensions_tsne = np.load(\"tsne_results.npy\")\n",
    "lables = np.load(\"kmeans_results_100.npy\")\n",
    "plot_dimensionality_reduction(dimensions_tsne, labels=lables, output_file=\"plot_tsne_2d.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "images_to_plot = [435873, 23657, 436051, 42668, 431471, 435909]\n",
    "plot_selected_images(images_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
