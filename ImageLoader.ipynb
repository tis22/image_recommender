{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ExifTags\n",
    "import uuid\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "from scipy.spatial import distance \n",
    "from sklearn.metrics import pairwise_distances\n",
    "from numba import jit, prange\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import pairwise\n",
    "import time\n",
    "import sqlite3\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrival Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number found images: 2056\n",
      "Some paths:\n",
      "C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\\DIV2k\\DIV2K_train_HR\\DIV2K_train_HR\\0001.png\n",
      "C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\\DIV2k\\DIV2K_train_HR\\DIV2K_train_HR\\0002.png\n",
      "C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\\DIV2k\\DIV2K_train_HR\\DIV2K_train_HR\\0003.png\n",
      "C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\\DIV2k\\DIV2K_train_HR\\DIV2K_train_HR\\0004.png\n",
      "C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\\DIV2k\\DIV2K_train_HR\\DIV2K_train_HR\\0005.png\n",
      "C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\\DIV2k\\DIV2K_train_HR\\DIV2K_train_HR\\0006.png\n",
      "C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\\DIV2k\\DIV2K_train_HR\\DIV2K_train_HR\\0007.png\n",
      "C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\\DIV2k\\DIV2K_train_HR\\DIV2K_train_HR\\0008.png\n",
      "C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\\DIV2k\\DIV2K_train_HR\\DIV2K_train_HR\\0009.png\n",
      "C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\\DIV2k\\DIV2K_train_HR\\DIV2K_train_HR\\0010.png\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 70.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "Load all image paths and get the total number of images,\n",
    "we can't use tqdm here, because we have to determine the number of images first.\n",
    "'''\n",
    "\n",
    "def find_image_files(root_dir, extensions=('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif')):\n",
    "    image_files = []\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(extensions):\n",
    "                image_files.append(os.path.join(subdir, file))\n",
    "    return image_files\n",
    "\n",
    "\n",
    "image_paths = find_image_files(r\"C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\")\n",
    "#df_image_paths = pd.DataFrame({'ID': range(1, len(image_paths) + 1), 'Path': image_paths})\n",
    "#df_image_paths = pd.DataFrame(image_paths, columns=[\"Path\"])\n",
    "#df_image_paths.to_pickle('Path.pkl')\n",
    "\n",
    "# Show first 10 paths\n",
    "print(f\"Number found images: {len(image_paths)}\")\n",
    "if len(image_paths) > 10:\n",
    "    print(\"Some paths:\")\n",
    "    for pic_path in image_paths[:10]:\n",
    "        print(pic_path)\n",
    "else:\n",
    "    print(\"Found paths:\", image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement functions (1st & 2nd)\n",
    "\n",
    "def image_rgb_calculation(image):\n",
    "    # OpenCV uses BGR color space, we have to convert it to the RGB color space\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Calculate the histogram\n",
    "    hist = cv2.calcHist([rgb_image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    \n",
    "    # Normalize the histogram so that histograms of different images (different sizes, resolutions) are comparable\n",
    "    hist = cv2.normalize(hist, hist)\n",
    "    hist = hist.flatten()\n",
    "    return hist\n",
    "\n",
    "def image_hsv_calculation(image):\n",
    "    # OpenCV uses BGR color space, we have to convert it to the RGB color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Calculate the histogram (bin-sizes = 8, values from 0-255)\n",
    "    hist = cv2.calcHist([hsv_image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    \n",
    "    # Normalize the histogram so that histograms of different images (different sizes, resolutions) are comparable\n",
    "    hist = cv2.normalize(hist, hist)\n",
    "    hist = hist.flatten()\n",
    "    return hist\n",
    "\n",
    "# To be implemented:\n",
    "def model_embeddings_calculation(model, image):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a781dc83375345ba80ff0e45aa17ee98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.336425, 0.019351881, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.9998705, 0.00057862874, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.25492105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[0.7242774, 0.013039364, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>[0.7743936, 0.0060108174, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>[0.035986535, 0.0071973074, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>[0.052002728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>[0.029992608, 0.00085693167, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>[0.40314555, 0.00842813, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>[0.36437201, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>[0.20665304, 0.016907977, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>[0.2258655, 0.015666971, 0.001305581, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>[0.10874878, 0.07299575, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>[0.2071246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>[0.4422131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                               Path\n",
       "0    1  [0.336425, 0.019351881, 0.0, 0.0, 0.0, 0.0, 0....\n",
       "1    2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2    3  [0.9998705, 0.00057862874, 0.0, 0.0, 0.0, 0.0,...\n",
       "3    5  [0.25492105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
       "4    6  [0.7242774, 0.013039364, 0.0, 0.0, 0.0, 0.0, 0...\n",
       "5    7  [0.7743936, 0.0060108174, 0.0, 0.0, 0.0, 0.0, ...\n",
       "6    8  [0.035986535, 0.0071973074, 0.0, 0.0, 0.0, 0.0...\n",
       "7    9  [0.052002728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....\n",
       "8   10  [0.029992608, 0.00085693167, 0.0, 0.0, 0.0, 0....\n",
       "9   11  [0.40314555, 0.00842813, 0.0, 0.0, 0.0, 0.0, 0...\n",
       "10  12  [0.36437201, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
       "11  13  [0.20665304, 0.016907977, 0.0, 0.0, 0.0, 0.0, ...\n",
       "12  14  [0.2258655, 0.015666971, 0.001305581, 0.0, 0.0...\n",
       "13  15  [0.10874878, 0.07299575, 0.0, 0.0, 0.0, 0.0, 0...\n",
       "14  16  [0.2071246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "15  17  [0.4422131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 0\n",
    "\n",
    "def image_batch_generator(image_files, batch_size, rezise_size, show_progress=True):\n",
    "    total_batches = (len(image_files) + batch_size - 1) // batch_size\n",
    "    progress_bar = tqdm(total=total_batches, desc=\"Processing images\") if show_progress else None\n",
    "    \n",
    "    \n",
    "    rgb_hists = []\n",
    "    hsv_hists = []\n",
    "    paths = []\n",
    "    \n",
    "    \n",
    "    for index in range(0, len(image_files), batch_size):\n",
    "        batch = image_files[index:index + batch_size]\n",
    "        \n",
    "        for i, path in enumerate(batch):\n",
    "            image = cv2.imread(path)\n",
    "            i = 1 + index + i\n",
    "            if image is not None:\n",
    "                try:\n",
    "                    image = cv2.resize(image, rezise_size)\n",
    "                    rgb_histogram = image_rgb_calculation(image)\n",
    "                    hsv_histogram = image_hsv_calculation(image)\n",
    "                    \n",
    "                    rgb_hists.append((i, rgb_histogram))\n",
    "                    hsv_hists.append((i, hsv_histogram))\n",
    "                    paths.append((i, path))\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Failed processing {path}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        #yield df, image_vectors\n",
    "        if show_progress:\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    if show_progress:\n",
    "        progress_bar.close()\n",
    "    \n",
    "    return rgb_hists, hsv_hists, paths\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "desired_size = (60, 60)\n",
    "\n",
    "rgb_hists, hsv_hists, paths = image_batch_generator(image_paths, batch_size, desired_size, show_progress=True)\n",
    "\n",
    "df_rgb = pd.DataFrame(rgb_hists, columns=[\"ID\", \"Histogram\"])\n",
    "df_paths = pd.DataFrame(rgb_hists, columns=[\"ID\", \"Path\"])\n",
    "df_rgb.to_pickle('RGB_Hist.pkl')\n",
    "df_paths.to_pickle('Path.pkl')\n",
    "df_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496c04dda43e44feb89ae1f2569d652a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 51\u001b[0m\n\u001b[0;32m     47\u001b[0m desired_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m     50\u001b[0m rgb_hists, hsv_hists, paths \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m image_batch_generator(image_paths, batch_size, desired_size, show_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     52\u001b[0m     paths\u001b[38;5;241m.\u001b[39mextend(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPath\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m     53\u001b[0m     rgb_hists\u001b[38;5;241m.\u001b[39mextend(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB_Histogram\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist())\n",
      "Cell \u001b[1;32mIn[6], line 33\u001b[0m, in \u001b[0;36mimage_batch_generator\u001b[1;34m(image_files, batch_size, resize_size, show_progress)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(image_files), batch_size):\n\u001b[0;32m     32\u001b[0m     batch \u001b[38;5;241m=\u001b[39m image_files[index:index \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m---> 33\u001b[0m     details_list \u001b[38;5;241m=\u001b[39m [extract_image_details(index \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, path, resize_size) \u001b[38;5;28;01mfor\u001b[39;00m i, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch)]\n\u001b[0;32m     34\u001b[0m     details_list \u001b[38;5;241m=\u001b[39m [features \u001b[38;5;28;01mfor\u001b[39;00m features \u001b[38;5;129;01min\u001b[39;00m details_list \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     35\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(details_list)\n",
      "Cell \u001b[1;32mIn[6], line 33\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(image_files), batch_size):\n\u001b[0;32m     32\u001b[0m     batch \u001b[38;5;241m=\u001b[39m image_files[index:index \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m---> 33\u001b[0m     details_list \u001b[38;5;241m=\u001b[39m [extract_image_details(index \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, path, resize_size) \u001b[38;5;28;01mfor\u001b[39;00m i, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch)]\n\u001b[0;32m     34\u001b[0m     details_list \u001b[38;5;241m=\u001b[39m [features \u001b[38;5;28;01mfor\u001b[39;00m features \u001b[38;5;129;01min\u001b[39;00m details_list \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     35\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(details_list)\n",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m, in \u001b[0;36mextract_image_details\u001b[1;34m(image_id, path, resize_size)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_image_details\u001b[39m(image_id, path, resize_size):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m         image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path)\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m             image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, resize_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Different Version 1 (less data)\n",
    "\n",
    "\n",
    "def extract_image_details(image_id, path, resize_size):\n",
    "    try:\n",
    "        image = cv2.imread(path)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, resize_size)\n",
    "            rgb_histogram = image_rgb_calculation(image)\n",
    "            hsv_histogram = image_hsv_calculation(image)\n",
    "            return {\n",
    "                'ID': image_id,\n",
    "                'Path': path,\n",
    "                'RGB_Histogram': rgb_histogram,\n",
    "                'HSV_Histogram': hsv_histogram\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            print(f\"Image at path {path} is None.\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed processing {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def image_batch_generator(image_files, batch_size, resize_size, show_progress=True):\n",
    "    total_batches = (len(image_files) + batch_size - 1) // batch_size\n",
    "    progress_bar = tqdm(total=total_batches, desc=\"Processing images\") if show_progress else None\n",
    "\n",
    "    for index in range(0, len(image_files), batch_size):\n",
    "        batch = image_files[index:index + batch_size]\n",
    "        details_list = [extract_image_details(index + i + 1, path, resize_size) for i, path in enumerate(batch)]\n",
    "        details_list = [features for features in details_list if features is not None]\n",
    "        df = pd.DataFrame(details_list)\n",
    "        yield df\n",
    "        if show_progress:\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    if show_progress:\n",
    "        progress_bar.close()\n",
    "\n",
    "        \n",
    "        \n",
    "# Beispielaufruf\n",
    "batch_size = 100\n",
    "desired_size = (60, 60)\n",
    "\n",
    "\n",
    "rgb_hists, hsv_hists, paths = [], [], []\n",
    "for df in image_batch_generator(image_paths, batch_size, desired_size, show_progress=True):\n",
    "    paths.extend(df[['ID', 'Path']].values.tolist())\n",
    "    rgb_hists.extend(df[['ID', 'RGB_Histogram']].values.tolist())\n",
    "    hsv_hists.extend(df[['ID', 'HSV_Histogram']].values.tolist())\n",
    "    \n",
    "\n",
    "df_rgb = pd.DataFrame(rgb_hists, columns=[\"ID\", \"Histogram\"])\n",
    "df_hsv = pd.DataFrame(hsv_hists, columns=[\"ID\", \"Histogram\"])\n",
    "df_paths = pd.DataFrame(paths, columns=[\"ID\", \"Path\"])\n",
    "\n",
    "df_rgb.to_pickle('RGB_Hist.pkl')\n",
    "df_hsv.to_pickle('HSV_Hist.pkl')\n",
    "df_paths.to_pickle('Path.pkl')\n",
    "\n",
    "print(df_rgb.head())\n",
    "print(df_hsv.head())\n",
    "print(df_paths.head())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84edbb8f6a8b43d3964bb6e1e74fd668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 115\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Load checkpoint\u001b[39;00m\n\u001b[0;32m    112\u001b[0m start_index, paths, rgb_hists, hsv_hists, other_data \u001b[38;5;241m=\u001b[39m load_checkpoint()\n\u001b[1;32m--> 115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df, batch_index \u001b[38;5;129;01min\u001b[39;00m image_batch_generator(image_paths, batch_size, desired_size, start_index\u001b[38;5;241m=\u001b[39mstart_index, show_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    116\u001b[0m     paths\u001b[38;5;241m.\u001b[39mextend(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPath\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m    117\u001b[0m     rgb_hists\u001b[38;5;241m.\u001b[39mextend(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB_Histogram\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist())\n",
      "Cell \u001b[1;32mIn[32], line 94\u001b[0m, in \u001b[0;36mimage_batch_generator\u001b[1;34m(image_files, batch_size, resize_size, start_index, show_progress)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_index, \u001b[38;5;28mlen\u001b[39m(image_files), batch_size):\n\u001b[0;32m     93\u001b[0m     batch \u001b[38;5;241m=\u001b[39m image_files[index:index \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m---> 94\u001b[0m     details_list \u001b[38;5;241m=\u001b[39m [extract_image_details(index \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, path, resize_size) \u001b[38;5;28;01mfor\u001b[39;00m i, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch)]\n\u001b[0;32m     95\u001b[0m     details_list \u001b[38;5;241m=\u001b[39m [features \u001b[38;5;28;01mfor\u001b[39;00m features \u001b[38;5;129;01min\u001b[39;00m details_list \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     96\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(details_list)\n",
      "Cell \u001b[1;32mIn[32], line 94\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_index, \u001b[38;5;28mlen\u001b[39m(image_files), batch_size):\n\u001b[0;32m     93\u001b[0m     batch \u001b[38;5;241m=\u001b[39m image_files[index:index \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m---> 94\u001b[0m     details_list \u001b[38;5;241m=\u001b[39m [extract_image_details(index \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, path, resize_size) \u001b[38;5;28;01mfor\u001b[39;00m i, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch)]\n\u001b[0;32m     95\u001b[0m     details_list \u001b[38;5;241m=\u001b[39m [features \u001b[38;5;28;01mfor\u001b[39;00m features \u001b[38;5;129;01min\u001b[39;00m details_list \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     96\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(details_list)\n",
      "Cell \u001b[1;32mIn[32], line 43\u001b[0m, in \u001b[0;36mextract_image_details\u001b[1;34m(image_id, path, resize_size)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Extract metadata\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m     exif_data \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39m_getexif()\n\u001b[0;32m     44\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m {ExifTags\u001b[38;5;241m.\u001b[39mTAGS\u001b[38;5;241m.\u001b[39mget(k, k): v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m exif_data\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mif\u001b[39;00m exif_data \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PIL\\PngImagePlugin.py:1010\u001b[0m, in \u001b[0;36mPngImageFile._getexif\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getexif\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexif\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo:\n\u001b[1;32m-> 1010\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexif\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw profile type exif\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo:\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PIL\\ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Different Version 2 (more data)\n",
    "\n",
    "\n",
    "def extract_image_details(image_id, path, resize_size):\n",
    "    try:\n",
    "        image = cv2.imread(path)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, resize_size)\n",
    "            rgb_histogram = image_rgb_calculation(image)\n",
    "            hsv_histogram = image_hsv_calculation(image)\n",
    "            \n",
    "            \n",
    "            ### several more informations ###\n",
    "            \n",
    "            # Resize image\n",
    "            resized_image = cv2.resize(image, resize_size)\n",
    "            \n",
    "            # Flatten image\n",
    "            resized_image_vector = resized_image.flatten()\n",
    "            \n",
    "            # Convert to RGB\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Calculate average color and brightness\n",
    "            avg_color = np.mean(image_rgb, axis=(0, 1)).tolist()\n",
    "            avg_brightness = np.mean(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "            # Convert to HSV and calculate average HSV\n",
    "            image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            avg_hsv = np.mean(image_hsv, axis=(0, 1)).tolist()\n",
    "\n",
    "            # File details\n",
    "            file_size = os.path.getsize(path)\n",
    "            file_type = os.path.splitext(path)[1]\n",
    "\n",
    "            with Image.open(path) as img:\n",
    "                # Resolution and DPI\n",
    "                resolution = img.size  # (width, height)\n",
    "                dpi = img.info.get('dpi', (0, 0))\n",
    "                \n",
    "                # Extract metadata\n",
    "                try:\n",
    "                    exif_data = img._getexif()\n",
    "                    metadata = {ExifTags.TAGS.get(k, k): v for k, v in exif_data.items()} if exif_data else {}\n",
    "                except AttributeError:\n",
    "                    metadata = {}\n",
    "            \n",
    "            \n",
    "            #################################\n",
    "            \n",
    "            \n",
    "            return {\n",
    "                'ID': image_id,\n",
    "                'Path': path,\n",
    "                'RGB_Histogram': rgb_histogram,\n",
    "                'HSV_Histogram': hsv_histogram,\n",
    "                'Average_Color': avg_color,\n",
    "                'Brightness': avg_brightness,\n",
    "                'Average_HSV': avg_hsv,\n",
    "                'Resolution': resolution,\n",
    "                'DPI': dpi,\n",
    "                'File_Size': file_size,\n",
    "                'File_Type': file_type,\n",
    "                'Metadata': metadata,\n",
    "                'Resized_Image_Vector': resized_image_vector\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            print(f\"Image at path {path} is None.\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed processing {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "def load_checkpoint():\n",
    "    if not os.path.exists('checkpoint.pkl'):\n",
    "        return 0, [], [], [], []\n",
    "    \n",
    "    with open('checkpoint.pkl', 'rb') as f:\n",
    "        batch_index, paths, rgb_hists, hsv_hists, other_data = pickle.load(f)\n",
    "\n",
    "    return batch_index, paths, rgb_hists, hsv_hists, other_data\n",
    "    \n",
    "    \n",
    "\n",
    "def image_batch_generator(image_files, batch_size, resize_size, start_index = 0, show_progress=True):\n",
    "    total_batches = (len(image_files) - start_index + batch_size - 1) // batch_size # - start_index to display remaining batches correctly\n",
    "    progress_bar = tqdm(total=total_batches, desc=\"Processing images\") if show_progress else None\n",
    "\n",
    "    for index in range(start_index, len(image_files), batch_size):\n",
    "        batch = image_files[index:index + batch_size]\n",
    "        details_list = [extract_image_details(index + i + 1, path, resize_size) for i, path in enumerate(batch)]\n",
    "        details_list = [features for features in details_list if features is not None]\n",
    "        df = pd.DataFrame(details_list)\n",
    "        yield df, index + batch_size\n",
    "        if show_progress:\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    if show_progress:\n",
    "        progress_bar.close()\n",
    "\n",
    "        \n",
    "        \n",
    "# Testing: Example\n",
    "batch_size = 100\n",
    "desired_size = (60, 60)\n",
    "\n",
    "\n",
    "# Load checkpoint\n",
    "start_index, paths, rgb_hists, hsv_hists, other_data = load_checkpoint()\n",
    "\n",
    "\n",
    "for df, batch_index in image_batch_generator(image_paths, batch_size, desired_size, start_index=start_index, show_progress=True):\n",
    "    paths.extend(df[['ID', 'Path']].values.tolist())\n",
    "    rgb_hists.extend(df[['ID', 'RGB_Histogram']].values.tolist())\n",
    "    hsv_hists.extend(df[['ID', 'HSV_Histogram']].values.tolist())\n",
    "    other_data.extend(df.drop(columns=['Path', 'RGB_Histogram', 'HSV_Histogram']).values.tolist())\n",
    "    \n",
    "    # Save checkpoint, overrides old one and appends new data\n",
    "    with open('checkpoint.pkl', 'wb') as f:\n",
    "        pickle.dump((batch_index, paths, rgb_hists, hsv_hists, other_data), f)\n",
    "    \n",
    "\n",
    "# Save results\n",
    "df_rgb = pd.DataFrame(rgb_hists, columns=[\"ID\", \"Histogram\"])\n",
    "df_hsv = pd.DataFrame(hsv_hists, columns=[\"ID\", \"Histogram\"])\n",
    "df_paths = pd.DataFrame(paths, columns=[\"ID\", \"Path\"])\n",
    "df_other_data = pd.DataFrame(other_data, columns=[\"ID\", \"Average_Color\",\n",
    "                                                 \"Brightness\", \"Average_HSV\",\n",
    "                                                 \"Resolution\",\"DPI\",\n",
    "                                                 \"File_Size\", \"File_Type\",\n",
    "                                                 \"Metadata\", \"Resized_Image_Vector\"\n",
    "                                                ])\n",
    " \n",
    "df_rgb.to_pickle('RGB_Hist.pkl')\n",
    "df_hsv.to_pickle('HSV_Hist.pkl')\n",
    "df_paths.to_pickle('Path.pkl')\n",
    "df_other_data.to_pickle('Other_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index, paths, rgb_hists, hsv_hists, other_data = load_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID                                          Histogram\n",
      "11  13  [0.20665304, 0.016907977, 0.0, 0.0, 0.0, 0.0, ...\n",
      "12  14  [0.2258655, 0.015666971, 0.001305581, 0.0, 0.0...\n",
      "13  15  [0.10874878, 0.07299575, 0.0, 0.0, 0.0, 0.0, 0...\n",
      "14  16  [0.2071246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
      "15  17  [0.4422131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
      "    ID                                          Histogram\n",
      "11  13  [0.011075616, 0.0, 0.005537808, 0.044302464, 0...\n",
      "12  14  [0.008913387, 0.002546682, 0.002546682, 0.0050...\n",
      "13  15  [0.01610175, 0.050094333, 0.028625334, 0.01789...\n",
      "14  16  [0.034017637, 0.014323216, 0.030436834, 0.0429...\n",
      "15  17  [0.018316956, 0.0033303557, 0.0016651779, 0.00...\n",
      "    ID                                               Path\n",
      "11  13  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
      "12  14  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
      "13  15  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
      "14  16  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
      "15  17  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
      "    ID                                      Average_Color  Brightness  \\\n",
      "11  13  [167.24444444444444, 121.20972222222223, 95.98...  132.094722   \n",
      "12  14  [135.36527777777778, 137.16361111111112, 135.1...  136.389167   \n",
      "13  15  [114.55916666666667, 117.08361111111111, 93.26...  113.618611   \n",
      "14  16  [125.15194444444444, 115.61194444444445, 84.76...  114.945000   \n",
      "15  17  [112.56527777777778, 94.01194444444444, 77.400...   97.663056   \n",
      "\n",
      "                                          Average_HSV    Resolution     DPI  \\\n",
      "11   [66.175, 114.28861111111111, 172.48916666666668]  (2040, 1356)  (0, 0)   \n",
      "12  [48.07388888888889, 83.45805555555556, 157.143...  (2040, 1524)  (0, 0)   \n",
      "13  [50.50861111111111, 83.17305555555555, 130.586...  (2040, 1644)  (0, 0)   \n",
      "14  [27.09861111111111, 93.83305555555556, 127.643...  (2040, 1356)  (0, 0)   \n",
      "15  [28.726111111111113, 101.39805555555556, 114.0...  (2040, 1356)  (0, 0)   \n",
      "\n",
      "    File_Size File_Type Metadata  \\\n",
      "11    4877716      .png       {}   \n",
      "12    5741871      .png       {}   \n",
      "13    6114081      .png       {}   \n",
      "14    4964392      .png       {}   \n",
      "15    4620733      .png       {}   \n",
      "\n",
      "                                 Resized_Image_Vector  \n",
      "11  [156, 169, 203, 146, 157, 187, 117, 129, 163, ...  \n",
      "12  [231, 176, 92, 235, 183, 102, 239, 189, 113, 4...  \n",
      "13  [82, 125, 167, 95, 139, 174, 120, 156, 193, 93...  \n",
      "14  [97, 136, 149, 75, 123, 125, 92, 139, 141, 63,...  \n",
      "15  [64, 91, 132, 12, 20, 47, 64, 124, 129, 29, 51...  \n"
     ]
    }
   ],
   "source": [
    "print(df_rgb.tail())\n",
    "print(df_hsv.tail())\n",
    "print(df_paths.tail())\n",
    "print(df_other_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database\n",
    "\n",
    "# Check if the folder 'databases' does not exist / create it\n",
    "if not os.path.exists('database'):\n",
    "    os.makedirs('database')\n",
    "    \n",
    "conn = sqlite3.connect(\"database/bd_database.db\")\n",
    "curs = conn.cursor()\n",
    "\n",
    "curs.execute(\"\"\"CREATE TABLE IF NOT EXISTS image_paths \n",
    "                (ID INTEGER PRIMARY KEY,\n",
    "                Path text);\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to database\n",
    "path_pickle_df = pd.read_pickle(\"Path.pkl\")\n",
    "\n",
    "for file_path in path_pickle_df['Path']:\n",
    "    curs.execute('''INSERT OR IGNORE INTO image_paths (Path) VALUES (?);''', (file_path,))\n",
    "    # print(f\"Inserted path: {file_path}\")\n",
    "    \n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\0031.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\adam-bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\adrian-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                               Path\n",
       "0    1    C:\\Users\\timsa\\Desktop\\sample_pictures\\0031.png\n",
       "1    2  C:\\Users\\timsa\\Desktop\\sample_pictures\\adam-bi...\n",
       "2    3  C:\\Users\\timsa\\Desktop\\sample_pictures\\adrian-...\n",
       "3    4  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "4    5  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "5    6  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "6    7  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "7    8  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "8    9  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "9   10  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "10  11  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "11  12  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "12  13  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "13  14  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "14  15  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "15  16  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curs.execute(\"\"\"SELECT *\n",
    "                FROM image_paths;\"\"\")\n",
    "results = curs.fetchall()\n",
    "\n",
    "df = pd.DataFrame(results, columns=['ID', 'Path'])\n",
    "\n",
    "#conn.close()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity functions\n",
    "\n",
    "def euclidean_distance():\n",
    "    pass\n",
    "\n",
    "def manhattan_distance():\n",
    "    pass\n",
    "\n",
    "def cosine_similarity():\n",
    "    pass\n",
    "\n",
    "def jaccard_similarity():\n",
    "    pass\n",
    "\n",
    "def hamming_distance():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parts for measurment - dimensionality reduction\n",
    "# needs 1-D-vector\n",
    "\n",
    "\n",
    "def extract_image_details(image_path):\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img = img.convert('RGB')  # Convert to RGB\n",
    "\n",
    "            # Resize image\n",
    "            img_cv = cv2.imread(image_path)\n",
    "            resized = cv2.resize(img_cv, desired_size)\n",
    "            img_as_1d = np.array(resized).flatten() #this could be parallelized\n",
    "\n",
    "            # UUID\n",
    "            unique_id = str(uuid.uuid4())\n",
    "\n",
    "        return {\n",
    "            'ID': unique_id,\n",
    "            'File_Path': image_path,\n",
    "            'Resized_Image_Vector': img_as_1d\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_large_image_dataset(generator, total_images, batch_size, n_components):\n",
    "    \"\"\"\n",
    "    Processes a large image dataset using IncrementalPCA in batches.\n",
    "\n",
    "    Parameters:\n",
    "    generator (generator): Generator yielding batches of image data.\n",
    "    total_images (int): Total number of images in the dataset.\n",
    "    batch_size (int): Number of images to process in each batch.\n",
    "    n_components (int): Number of principal components to keep.\n",
    "\n",
    "    Returns:\n",
    "    IncrementalPCA: The fitted IncrementalPCA model.\n",
    "    \"\"\"\n",
    "    ipca = IncrementalPCA(n_components=n_components)\n",
    "    \n",
    "    for _ in range(0, total_images, batch_size):\n",
    "        batch_df, image_vectors = next(generator)\n",
    "        ipca.partial_fit(image_vectors)\n",
    "    \n",
    "    return ipca\n",
    "\n",
    "\n",
    "def transform_image_features(batch_df, image_vectors, ipca):\n",
    "    \"\"\"\n",
    "    Transforms image features using PCA.\n",
    "\n",
    "    Parameters:\n",
    "    batch_df (pd.DataFrame): The DataFrame containing batch image details.\n",
    "    image_vectors (np.array): The array of image vectors.\n",
    "    ipca (IncrementalPCA): The pre-fitted IncrementalPCA.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The updated DataFrame with PCA vectors added.\n",
    "    \"\"\"\n",
    "    pca_vectors = ipca.transform(image_vectors)\n",
    "    batch_df['PCA_Vectors'] = list(pca_vectors)\n",
    "    return batch_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_batch_generator(image_files, batch_size, show_progress=True):\n",
    "    total_batches = (len(image_files) + batch_size - 1) // batch_size\n",
    "    progress_bar = tqdm(total=total_batches, desc=\"Processing images\") if show_progress else None\n",
    "\n",
    "    for index in range(0, len(image_files), batch_size):\n",
    "        batch = image_files[index:index + batch_size]\n",
    "        details_list = [extract_image_details(image) for image in batch]\n",
    "        details_list = [features for features in details_list if features is not None]\n",
    "        image_vectors = np.array([features['Resized_Image_Vector'] for features in details_list])\n",
    "        df = pd.DataFrame(details_list)\n",
    "        yield df, image_vectors\n",
    "        if show_progress:\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    if show_progress:\n",
    "        progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79ebbefebbc4201b27268f4077e15f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing C:\\Users\\timsa\\Desktop\\sample_pictures\\test_2.bmp: cannot identify image file 'C:\\\\Users\\\\timsa\\\\Desktop\\\\sample_pictures\\\\test_2.bmp'\n",
      "Error processing C:\\Users\\timsa\\Desktop\\sample_pictures\\test_2.bmp: cannot identify image file 'C:\\\\Users\\\\timsa\\\\Desktop\\\\sample_pictures\\\\test_2.bmp'\n"
     ]
    }
   ],
   "source": [
    "# Execution of code\n",
    "\n",
    "total_images = len(image_paths)\n",
    "batch_size = 100\n",
    "desired_size = (60, 60)   # size which the images will be resized to\n",
    "n_components = 10 # the amount of features our iPCA will keep for every image\n",
    "\n",
    "generator = image_batch_generator(image_paths, batch_size, show_progress=True)   # gives back batch_df + image as 1d\n",
    "ipca = process_large_image_dataset(generator, total_images, batch_size, n_components) # needed to fit the iPCA \n",
    "\n",
    "# After fitting IPCA, transform all data\n",
    "for batch_df, image_vectors in image_batch_generator(image_paths, batch_size, show_progress=False):\n",
    "    transformed_batch_df = transform_image_features(batch_df, image_vectors, ipca)\n",
    "\n",
    "    \n",
    "    transformed_batch_df.head()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Resized_Image_Vector</th>\n",
       "      <th>PCA_Vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34b0bb62-1f7b-45a8-8fc4-eaedddb5757f</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\0031.png</td>\n",
       "      <td>[195, 187, 177, 188, 167, 162, 144, 123, 139, ...</td>\n",
       "      <td>[496.6541985933603, -888.0665161932402, -3756....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8c0dfbb5-bba4-409d-8b57-849ce8bde435</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\adam-bi...</td>\n",
       "      <td>[222, 212, 208, 224, 213, 207, 225, 216, 209, ...</td>\n",
       "      <td>[12632.571816986021, -259.16952814348303, 2069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e07de2bc-620f-4a07-b2b9-653b6c86f0b6</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\adrian-...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-11009.597883374357, -501.0693401087662, -502...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d332eb0a-e650-4c85-a5ae-cec91dfc3c8c</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "      <td>[98, 98, 94, 41, 48, 38, 20, 32, 32, 14, 26, 2...</td>\n",
       "      <td>[-3963.8594334778113, 2623.8053094494276, 1098...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47e15f53-ee2d-42ac-81c7-a4e302982c86</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "      <td>[55, 51, 61, 36, 27, 30, 110, 51, 32, 161, 113...</td>\n",
       "      <td>[-4741.879883035555, -2071.263536722551, 1369....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "0  34b0bb62-1f7b-45a8-8fc4-eaedddb5757f   \n",
       "1  8c0dfbb5-bba4-409d-8b57-849ce8bde435   \n",
       "2  e07de2bc-620f-4a07-b2b9-653b6c86f0b6   \n",
       "3  d332eb0a-e650-4c85-a5ae-cec91dfc3c8c   \n",
       "4  47e15f53-ee2d-42ac-81c7-a4e302982c86   \n",
       "\n",
       "                                           File_Path  \\\n",
       "0    C:\\Users\\timsa\\Desktop\\sample_pictures\\0031.png   \n",
       "1  C:\\Users\\timsa\\Desktop\\sample_pictures\\adam-bi...   \n",
       "2  C:\\Users\\timsa\\Desktop\\sample_pictures\\adrian-...   \n",
       "3  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...   \n",
       "4  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...   \n",
       "\n",
       "                                Resized_Image_Vector  \\\n",
       "0  [195, 187, 177, 188, 167, 162, 144, 123, 139, ...   \n",
       "1  [222, 212, 208, 224, 213, 207, 225, 216, 209, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [98, 98, 94, 41, 48, 38, 20, 32, 32, 14, 26, 2...   \n",
       "4  [55, 51, 61, 36, 27, 30, 110, 51, 32, 161, 113...   \n",
       "\n",
       "                                         PCA_Vectors  \n",
       "0  [496.6541985933603, -888.0665161932402, -3756....  \n",
       "1  [12632.571816986021, -259.16952814348303, 2069...  \n",
       "2  [-11009.597883374357, -501.0693401087662, -502...  \n",
       "3  [-3963.8594334778113, 2623.8053094494276, 1098...  \n",
       "4  [-4741.879883035555, -2071.263536722551, 1369....  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_batch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                    16\n",
       "unique                                                   16\n",
       "top       [496.6541985933603, -888.0665161932402, -3756....\n",
       "freq                                                      1\n",
       "Name: PCA_Vectors, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_batch_df[\"PCA_Vectors\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12632.57181699,  -259.16952814,  2069.72584842,   444.01229774,\n",
       "         481.85474691,   -62.15674047,   918.43916599,   427.64807317,\n",
       "         293.81656367,   -74.17618535])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_batch_df[\"PCA_Vectors\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
