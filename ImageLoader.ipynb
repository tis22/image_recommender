{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ExifTags\n",
    "import uuid\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "from scipy.spatial import distance \n",
    "from sklearn.metrics import pairwise_distances\n",
    "from numba import jit, prange\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import pairwise\n",
    "import time\n",
    "import sqlite3\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrival Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load all image paths and get the total number of images,\n",
    "we can't use tqdm here, because we have to determine the number of images first.\n",
    "'''\n",
    "\n",
    "def find_image_files(root_dir, extensions=('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif')):\n",
    "    image_files = []\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(extensions):\n",
    "                image_files.append(os.path.join(subdir, file))\n",
    "    return image_files\n",
    "\n",
    "\n",
    "# here was: image_paths = find_image_files(r\"\")\n",
    "# df_image_paths = pd.DataFrame({'ID': range(1, len(image_paths) + 1), 'Path': image_paths})\n",
    "# df_image_paths = pd.DataFrame(image_paths, columns=[\"Path\"])\n",
    "# df_image_paths.to_pickle('Path.pkl')\n",
    "\n",
    "\n",
    "# Show first 10 paths\n",
    "# print(f\"Number found images: {len(image_paths)}\")\n",
    "# if len(image_paths) > 10:\n",
    "#     print(\"Some paths:\")\n",
    "#     for pic_path in image_paths[:10]:\n",
    "#         print(pic_path)\n",
    "# else:\n",
    "#     print(\"Found paths:\", image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement functions\n",
    "\n",
    "def image_rgb_calculation(image):\n",
    "    # OpenCV uses BGR color space, we have to convert it to the RGB color space\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Calculate the histogram\n",
    "    hist = cv2.calcHist([rgb_image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    \n",
    "    # Normalize the histogram so that histograms of different images (different sizes, resolutions) are comparable\n",
    "    hist = cv2.normalize(hist, hist)\n",
    "    hist = hist.flatten()\n",
    "    return hist\n",
    "\n",
    "\n",
    "def image_hsv_calculation(image):\n",
    "    # OpenCV uses BGR color space, we have to convert it to the RGB color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Calculate the histogram (bin-sizes = 8, values from 0-255)\n",
    "    hist = cv2.calcHist([hsv_image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    \n",
    "    # Normalize the histogram so that histograms of different images (different sizes, resolutions) are comparable\n",
    "    hist = cv2.normalize(hist, hist)\n",
    "    hist = hist.flatten()\n",
    "    return hist\n",
    "\n",
    "\n",
    "# Load the efficientnet_v2_s model\n",
    "model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)\n",
    "\n",
    "# Remove last layer (classificator), because we only need the features\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "model.eval()\n",
    "\n",
    "# Define preprocessing transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def model_embeddings_calculation(image):\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model(input_batch)\n",
    "    features = torch.flatten(features, 1)\n",
    "    \n",
    "    return features.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91132ec15a704a0bbd83641622d6a20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 21s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def extract_image_details(image_id, path, resize_size):\n",
    "    try:\n",
    "        image = cv2.imread(path)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, resize_size)\n",
    "            rgb_histogram = image_rgb_calculation(image)\n",
    "            hsv_histogram = image_hsv_calculation(image)\n",
    "            model_embedding = model_embeddings_calculation(image)\n",
    "            \n",
    "            ### several more informations ###\n",
    "            \n",
    "            # Convert to RGB\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Calculate average color and brightness\n",
    "            avg_color = np.mean(image_rgb, axis=(0, 1)).tolist()\n",
    "            avg_brightness = np.mean(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "            # Convert to HSV and calculate average HSV\n",
    "            image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            avg_hsv = np.mean(image_hsv, axis=(0, 1)).tolist()\n",
    "\n",
    "            # File details\n",
    "            file_size = os.path.getsize(path)\n",
    "            file_type = os.path.splitext(path)[1]\n",
    "\n",
    "            with Image.open(path) as img:\n",
    "                # Resolution and DPI\n",
    "                resolution = img.size  # (width, height)\n",
    "                dpi = img.info.get('dpi', (0, 0))\n",
    "                \n",
    "                # Extract metadata\n",
    "                try:\n",
    "                    exif_data = img._getexif()\n",
    "                    metadata = {ExifTags.TAGS.get(k, k): v for k, v in exif_data.items()} if exif_data else {}\n",
    "                except AttributeError:\n",
    "                    metadata = {}\n",
    "            \n",
    "            \n",
    "            #################################\n",
    "            \n",
    "            \n",
    "            return {\n",
    "                'ID': image_id,\n",
    "                'Path': path,\n",
    "                'RGB_Histogram': rgb_histogram,\n",
    "                'HSV_Histogram': hsv_histogram,\n",
    "                'Model_Embedding': model_embedding,\n",
    "                'Average_Color': avg_color,\n",
    "                'Brightness': avg_brightness,\n",
    "                'Average_HSV': avg_hsv,\n",
    "                'Resolution': resolution,\n",
    "                'DPI': dpi,\n",
    "                'File_Size': file_size,\n",
    "                'File_Type': file_type,\n",
    "                'Metadata': metadata\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            print(f\"Image at path {path} is None.\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed processing {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "def load_checkpoint():\n",
    "    if not os.path.exists('checkpoint.pkl'):\n",
    "        return 0, [], [], [], [], []\n",
    "    \n",
    "    with open('checkpoint.pkl', 'rb') as f:\n",
    "        batch_index, paths, rgb_hists, hsv_hists, embeddings, other_data = pickle.load(f)\n",
    "        print(f\"Loaded checkpoint.\\nStarting from path with ID: {batch_index + 1}\")\n",
    "\n",
    "    return batch_index, paths, rgb_hists, hsv_hists, embeddings, other_data\n",
    "    \n",
    "    \n",
    "\n",
    "def image_batch_generator(image_files, batch_size, resize_size, start_index = 0, show_progress=True):\n",
    "    total_batches = (len(image_files) - start_index + batch_size - 1) // batch_size # - start_index to display remaining batches correctly\n",
    "    progress_bar = tqdm(total=total_batches, desc=\"Processing images\") if show_progress else None\n",
    "\n",
    "    for index in range(start_index, len(image_files), batch_size):\n",
    "        batch = image_files[index:index + batch_size]\n",
    "        details_list = [extract_image_details(index + i + 1, path, resize_size) for i, path in enumerate(batch)]\n",
    "        details_list = [features for features in details_list if features is not None]\n",
    "        df = pd.DataFrame(details_list)\n",
    "        yield df, index + batch_size\n",
    "        if show_progress:\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    if show_progress:\n",
    "        progress_bar.close()\n",
    "\n",
    "        \n",
    "        \n",
    "# Testing: Example\n",
    "batch_size = 1000\n",
    "desired_size = (224, 224)\n",
    "\n",
    "\n",
    "# Load checkpoint\n",
    "start_index, paths, rgb_hists, hsv_hists, embeddings, other_data = load_checkpoint()\n",
    "\n",
    "image_paths = find_image_files(r\"C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\image_data\\extra_collection\\city\")\n",
    "\n",
    "for df, batch_index in image_batch_generator(image_paths, batch_size, desired_size, start_index=start_index, show_progress=True):\n",
    "    paths.extend(df[['ID', 'Path']].values.tolist())\n",
    "    rgb_hists.extend(df[['ID', 'RGB_Histogram']].values.tolist())\n",
    "    hsv_hists.extend(df[['ID', 'HSV_Histogram']].values.tolist())\n",
    "    embeddings.extend(df[['ID', 'Model_Embedding']].values.tolist())\n",
    "    other_data.extend(df.drop(columns=['Path', 'RGB_Histogram', 'HSV_Histogram', 'Model_Embedding']).values.tolist())\n",
    "    \n",
    "    # Save checkpoint, overrides old one and appends new data\n",
    "    with open('checkpoint.pkl', 'wb') as f:\n",
    "        pickle.dump((batch_index, paths, rgb_hists, hsv_hists, embeddings, other_data), f)\n",
    "    \n",
    "\n",
    "# Save results\n",
    "df_paths = pd.DataFrame(paths, columns=[\"ID\", \"Path\"])\n",
    "df_rgb = pd.DataFrame(rgb_hists, columns=[\"ID\", \"Histogram\"])\n",
    "df_hsv = pd.DataFrame(hsv_hists, columns=[\"ID\", \"Histogram\"])\n",
    "df_embeddings = pd.DataFrame(embeddings, columns=[\"ID\", \"Embedding\"])\n",
    "df_other_data = pd.DataFrame(other_data, columns=[\"ID\", \"Average_Color\",\n",
    "                                                 \"Brightness\", \"Average_HSV\",\n",
    "                                                 \"Resolution\",\"DPI\",\n",
    "                                                 \"File_Size\", \"File_Type\",\n",
    "                                                 \"Metadata\"\n",
    "                                                ])\n",
    "\n",
    "df_paths.to_pickle('Path.pkl')\n",
    "df_rgb.to_pickle('RGB_Hist.pkl')\n",
    "df_hsv.to_pickle('HSV_Hist.pkl')\n",
    "df_embeddings.to_pickle('Embedding.pkl')\n",
    "df_other_data.to_pickle('Other_data.pkl')\n",
    "\n",
    "# Checkpoint can be removed after program was successful\n",
    "if os.path.exists('checkpoint.pkl'):\n",
    "    os.remove('checkpoint.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2056"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID                                          Embedding\n",
      "2051  2052  [-0.20513535, -0.10810962, -0.23736508, -0.231...\n",
      "2052  2053  [-0.19108932, 1.7732646, -0.20176479, -0.16974...\n",
      "2053  2054  [-0.011624885, 0.011469968, -0.16959248, -0.23...\n",
      "2054  2055  [-0.15407062, 0.28345406, -0.1295455, -0.14643...\n",
      "2055  2056  [-0.18163215, 0.6147414, -0.068714134, -0.2097...\n"
     ]
    }
   ],
   "source": [
    "print(df_embeddings.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_histogram_length = len(df_embeddings.iloc[0]['Embedding'])\n",
    "first_histogram_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID                                          Histogram\n",
      "2051  2052  [0.04886454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "2052  2053  [0.5030495, 0.41761094, 0.0, 0.0, 0.0, 0.0, 0....\n",
      "2053  2054  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "2054  2055  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "2055  2056  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "        ID                                          Histogram\n",
      "2051  2052  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "2052  2053  [0.041315034, 0.004804074, 0.003843259, 0.0057...\n",
      "2053  2054  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "2054  2055  [0.0, 0.0, 0.0, 0.0, 0.0007018793, 0.006316913...\n",
      "2055  2056  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0038390239, 0.0665...\n",
      "        ID                                               Path\n",
      "2051  2052  C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\imag...\n",
      "2052  2053  C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\imag...\n",
      "2053  2054  C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\imag...\n",
      "2054  2055  C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\imag...\n",
      "2055  2056  C:\\Users\\timsa\\Desktop\\Daten_Joschua\\data\\imag...\n",
      "        ID                                      Average_Color  Brightness  \\\n",
      "2051  2052  [130.98166666666665, 165.39666666666668, 173.4...  156.016667   \n",
      "2052  2053  [40.61055555555556, 45.284166666666664, 45.523...   43.907222   \n",
      "2053  2054  [127.42722222222223, 175.6822222222222, 233.82...  167.870556   \n",
      "2054  2055  [193.6175, 204.1461111111111, 214.69861111111112]  202.188611   \n",
      "2055  2056  [106.96555555555555, 179.19583333333333, 201.6...  160.155556   \n",
      "\n",
      "                                            Average_HSV    Resolution  \\\n",
      "2051  [86.34444444444445, 90.84944444444444, 183.989...  (2471, 3103)   \n",
      "2052   [74.50055555555555, 174.9025, 64.83027777777778]  (3950, 4937)   \n",
      "2053  [107.13111111111111, 116.85527777777777, 233.8...  (4032, 3024)   \n",
      "2054   [104.32333333333334, 26.725, 215.32611111111112]  (5472, 3648)   \n",
      "2055  [90.37222222222222, 134.98416666666665, 203.62...  (5999, 3876)   \n",
      "\n",
      "           DPI  File_Size File_Type Metadata  \n",
      "2051  (72, 72)    2201212      .jpg       {}  \n",
      "2052  (72, 72)    4932275      .jpg       {}  \n",
      "2053  (72, 72)    1691620      .jpg       {}  \n",
      "2054  (72, 72)     660767      .jpg       {}  \n",
      "2055  (72, 72)    3313420      .jpg       {}  \n"
     ]
    }
   ],
   "source": [
    "print(df_rgb.tail())\n",
    "print(df_hsv.tail())\n",
    "print(df_paths.tail())\n",
    "print(df_other_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database\n",
    "\n",
    "# Check if the folder 'databases' does not exist / create it\n",
    "if not os.path.exists('database'):\n",
    "    os.makedirs('database')\n",
    "    \n",
    "conn = sqlite3.connect(\"database/bd_database.db\")\n",
    "curs = conn.cursor()\n",
    "\n",
    "curs.execute(\"\"\"CREATE TABLE IF NOT EXISTS image_paths \n",
    "                (ID INTEGER PRIMARY KEY,\n",
    "                Path text);\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to database\n",
    "path_pickle_df = pd.read_pickle(\"Path.pkl\")\n",
    "\n",
    "for file_path in path_pickle_df['Path']:\n",
    "    curs.execute('''INSERT OR IGNORE INTO image_paths (Path) VALUES (?);''', (file_path,))\n",
    "    # print(f\"Inserted path: {file_path}\")\n",
    "    \n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\0031.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\adam-bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\adrian-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                               Path\n",
       "0    1    C:\\Users\\timsa\\Desktop\\sample_pictures\\0031.png\n",
       "1    2  C:\\Users\\timsa\\Desktop\\sample_pictures\\adam-bi...\n",
       "2    3  C:\\Users\\timsa\\Desktop\\sample_pictures\\adrian-...\n",
       "3    4  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "4    5  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "5    6  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "6    7  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "7    8  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "8    9  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "9   10  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "10  11  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "11  12  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "12  13  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "13  14  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "14  15  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_...\n",
       "15  16  C:\\Users\\timsa\\Desktop\\sample_pictures\\folder_..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curs.execute(\"\"\"SELECT *\n",
    "                FROM image_paths;\"\"\")\n",
    "results = curs.fetchall()\n",
    "\n",
    "df = pd.DataFrame(results, columns=['ID', 'Path'])\n",
    "\n",
    "#conn.close()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity functions\n",
    "\n",
    "def euclidean_distance():\n",
    "    pass\n",
    "\n",
    "def manhattan_distance():\n",
    "    pass\n",
    "\n",
    "def cosine_similarity():\n",
    "    pass\n",
    "\n",
    "def jaccard_similarity():\n",
    "    pass\n",
    "\n",
    "def hamming_distance():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
